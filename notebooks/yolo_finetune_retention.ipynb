{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"A100","collapsed_sections":["MdF_bf3HsyJw","ErR6j1OSxz5j","lDqmqH1Vx3Uo","5_6Shtd-0tjp","Ez_nTrQOOcKl","LdDkCjf_TYbn"],"authorship_tag":"ABX9TyNFxfpdcnGesF21U9WsT5Qk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ğŸ“Š Evaluation: Vest Detection Knowledge Retention After Fine-Tuning on Helmet"],"metadata":{"id":"gmtIU-at8AzU"}},{"cell_type":"markdown","source":["\n","## ğŸ¯ Objective\n","Assess whether the YOLO model **retains its performance on the \"Safety-Vests\" class** after being fine-tuned on a new dataset containing only the \"Helmet\" class.\n","\n","---\n","\n","## ğŸ“ˆ Results Summary\n","\n","| Metric         | Before (Only Vest Trained) | After (Post Helmet Fine-Tuning) |\n","|----------------|----------------------------|----------------------------------|\n","| mAP50          | **0.995**                  | **0.106**                        |\n","| mAP50-95       | **0.940**                  | **0.0466**                       |\n","| Precision (P)  | **0.999**                  | **0.00978**                      |\n","| Recall (R)     | **1.000**                  | **0.939**                        |\n","\n","---\n","\n","## ğŸ§  Key Observations\n","\n","- **Severe forgetting occurred**: mAP dropped from **0.995 â†’ 0.106**, indicating that the model **lost most of its ability to detect vests** after fine-tuning on helmets.\n","- **Precision collapsed**, suggesting the model still tries to detect vests (due to preserved head structure), but predictions are now mostly incorrect.\n","- **Recall stayed high**, implying the model is still \"seeing\" vest-like objects, but associating them incorrectly.\n","\n","---\n","\n","## âœ… Interpretation\n","\n","Despite keeping the `'Safety-Vests'` class in the `.yaml` file during helmet training, the model **unlearned the vest knowledge** due to:\n","\n","- **Absence of vest labels in the second dataset**, causing vests to be treated as background\n","\n","---\n","\n","## ğŸ’¡ Next Step Suggestions\n","\n","- try **joint training** with merged datasets to avoid forgetting (didn't work)\n","- Try **freezing some layers** for class 0 (vest) during helmet training (didn't work)\n","- Explore annotating the datasets with missing classes' labels\n","(explored in another annotation notebook, best solution yet!)"],"metadata":{"id":"TuJc0WMpEvaq"}},{"cell_type":"markdown","source":["# ğŸ’» Experiment Implementation"],"metadata":{"id":"MdF_bf3HsyJw"}},{"cell_type":"markdown","source":["##### Setup"],"metadata":{"id":"ErR6j1OSxz5j"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"gw-rDtTirdhw","executionInfo":{"status":"ok","timestamp":1753123778947,"user_tz":-60,"elapsed":78417,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"002f34a4-c29f-4d04-caf4-0cd8fb8d51c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Install Ultralytics\n","!pip install ultralytics --quiet"]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import os\n","import shutil"],"metadata":{"id":"nzpgx9og4eKG","executionInfo":{"status":"ok","timestamp":1753123782509,"user_tz":-60,"elapsed":3547,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1c6426eb-f0f1-4bc1-e8a6-fadfaa25162b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file âœ… \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w89XFqQUs4_v","executionInfo":{"status":"ok","timestamp":1753123817097,"user_tz":-60,"elapsed":34575,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"09b3706a-a910-4e7d-fcad-b0598cbe6bf3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["##### ğŸ“Œ Phase 1: Fine-Tune on `vest` Only\n","\n"],"metadata":{"id":"lDqmqH1Vx3Uo"}},{"cell_type":"code","source":["# Load and train on vest dataset\n","model_vest = YOLO('yolov8n.pt')  # small model for speed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VC4tt5bmyDmO","executionInfo":{"status":"ok","timestamp":1752494579725,"user_tz":-120,"elapsed":3094,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"65dce8c3-6401-4cc9-8f87-4a5202fdc211"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 348MB/s]\n"]}]},{"cell_type":"code","source":["model_vest.train(\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml',\n","    epochs=20,\n","    imgsz=640,\n","    project='/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment',\n","    name='yolov8n_vest'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"9ihF8mIFx6sl","executionInfo":{"status":"ok","timestamp":1752494900388,"user_tz":-120,"elapsed":320659,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"a9cd4de0-6771-47af-e261-b4098e5a70d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.166 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_vest2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 109MB/s]"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 426MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 0.1Â±0.0 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [02:17<00:00,  6.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.1 ms, read: 0.1Â±0.0 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:12<00:00,  4.05it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/20      2.09G     0.9336      1.665      1.354          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:07<00:00,  7.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.66it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.776      0.615      0.685      0.482\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/20      2.31G     0.8772      1.086      1.253          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.688      0.635      0.802      0.577\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/20      2.34G      0.872     0.9186      1.242          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.87it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.793      0.812      0.849        0.6\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/20      2.36G     0.8456     0.8074      1.225          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.67it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.961          1      0.995      0.757\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/20      2.37G     0.7937     0.7003      1.187          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.89it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52          1      0.978      0.995      0.795\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/20      2.39G     0.7844     0.6597      1.176          6        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.96it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.981      0.994      0.994      0.784\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/20      2.41G     0.7525     0.6203      1.162          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.83it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.978          1      0.995      0.804\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/20      2.42G     0.7092     0.5381       1.12          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.59it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.995          1      0.995       0.82\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/20      2.44G     0.6659     0.5144      1.107          3        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52       0.98          1      0.995      0.857\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/20      2.46G     0.6633     0.4796      1.097          5        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.83it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52       0.96          1      0.994      0.821\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/20      2.47G     0.5746     0.4654      1.062          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:06<00:00,  8.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.31it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.865\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/20      2.49G     0.5206     0.4045      1.044          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.963      0.997      0.994      0.857\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/20      2.51G     0.5024     0.3747      1.015          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.867\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/20      2.53G     0.4604     0.3447     0.9711          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.859\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/20      2.54G     0.4376     0.3223     0.9614          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.865\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/20      2.56G     0.4122     0.3078     0.9544          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.904\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/20      2.58G     0.3758     0.2816      0.923          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995        0.9\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/20      2.59G     0.3584     0.2644     0.9137          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.899\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/20      2.61G      0.355     0.2595     0.9117          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00,  9.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.94it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.919\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/20      2.63G     0.3174     0.2416     0.8916          2        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:05<00:00, 10.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995      0.921\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","20 epochs completed in 0.036 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2/weights/last.pt, 6.2MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2/weights/best.pt, 6.2MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2/weights/best.pt...\n","Ultralytics 8.3.166 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.999          1      0.995       0.92\n","Speed: 0.2ms preprocess, 0.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([0])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x799482b03dd0>\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n","curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[        0.8,         0.8,     0.96933,     0.98442,     0.98782,     0.99048,     0.99049,      0.9905,     0.99052,     0.99053,     0.99054,     0.99055,     0.99056,     0.99058,     0.99059,      0.9906,     0.99061,     0.99062,     0.99064,     0.99065,     0.99066,     0.99067,     0.99069,\n","             0.9907,     0.99071,     0.99072,     0.99073,     0.99075,     0.99076,     0.99077,     0.99078,     0.99079,     0.99081,     0.99082,     0.99083,     0.99084,     0.99086,     0.99087,     0.99088,     0.99089,      0.9909,     0.99092,     0.99093,     0.99094,     0.99095,     0.99097,\n","            0.99098,     0.99099,       0.991,     0.99101,     0.99103,     0.99104,     0.99105,     0.99106,     0.99107,     0.99109,      0.9911,     0.99111,     0.99112,     0.99114,     0.99115,     0.99116,     0.99117,     0.99118,      0.9912,     0.99121,     0.99122,     0.99123,     0.99124,\n","            0.99126,     0.99127,     0.99128,     0.99129,     0.99131,     0.99132,     0.99133,     0.99134,     0.99135,     0.99137,     0.99138,     0.99139,      0.9914,     0.99141,     0.99143,     0.99144,     0.99145,     0.99146,     0.99148,     0.99149,      0.9915,     0.99151,     0.99152,\n","            0.99154,     0.99155,     0.99156,     0.99157,     0.99158,      0.9916,     0.99161,     0.99162,     0.99163,     0.99165,     0.99166,     0.99167,     0.99168,     0.99169,     0.99171,     0.99172,     0.99173,     0.99174,     0.99175,     0.99177,     0.99178,     0.99179,      0.9918,\n","            0.99182,     0.99183,     0.99184,     0.99185,     0.99186,     0.99188,     0.99189,      0.9919,     0.99191,     0.99192,     0.99194,     0.99195,     0.99196,     0.99197,     0.99199,       0.992,     0.99201,     0.99202,     0.99203,     0.99205,     0.99206,     0.99207,     0.99208,\n","            0.99209,     0.99211,     0.99212,     0.99213,     0.99214,     0.99215,     0.99217,     0.99218,     0.99219,      0.9922,     0.99222,     0.99223,     0.99224,     0.99225,     0.99226,     0.99228,     0.99229,      0.9923,     0.99231,     0.99232,     0.99234,     0.99235,     0.99236,\n","            0.99237,     0.99239,      0.9924,     0.99241,     0.99242,     0.99243,     0.99245,     0.99246,     0.99247,     0.99248,     0.99249,     0.99251,     0.99252,     0.99253,     0.99254,     0.99255,     0.99257,     0.99258,     0.99259,      0.9926,     0.99262,     0.99263,     0.99264,\n","            0.99265,     0.99266,     0.99268,     0.99269,      0.9927,     0.99271,     0.99272,     0.99274,     0.99275,     0.99276,     0.99277,     0.99278,      0.9928,     0.99281,     0.99282,     0.99283,     0.99285,     0.99286,     0.99287,     0.99288,     0.99289,     0.99291,     0.99292,\n","            0.99293,     0.99294,     0.99295,     0.99297,     0.99298,     0.99299,       0.993,     0.99301,     0.99303,     0.99304,     0.99305,     0.99306,     0.99308,     0.99309,      0.9931,     0.99311,     0.99312,     0.99314,     0.99315,     0.99316,     0.99317,     0.99318,      0.9932,\n","            0.99321,     0.99322,     0.99323,     0.99324,     0.99326,     0.99327,     0.99328,     0.99329,     0.99331,     0.99332,     0.99333,     0.99334,     0.99335,     0.99337,     0.99338,     0.99339,      0.9934,     0.99341,     0.99343,     0.99344,     0.99345,     0.99346,     0.99347,\n","            0.99349,      0.9935,     0.99351,     0.99352,     0.99354,     0.99355,     0.99356,     0.99357,     0.99358,      0.9936,     0.99361,     0.99362,     0.99363,     0.99364,     0.99366,     0.99367,     0.99368,     0.99369,      0.9937,     0.99372,     0.99373,     0.99374,     0.99375,\n","            0.99376,     0.99378,     0.99379,      0.9938,     0.99381,     0.99383,     0.99384,     0.99385,     0.99386,     0.99387,     0.99389,      0.9939,     0.99391,     0.99392,     0.99393,     0.99395,     0.99396,     0.99397,     0.99398,     0.99399,     0.99401,     0.99402,     0.99403,\n","            0.99404,     0.99405,     0.99407,     0.99408,     0.99409,      0.9941,     0.99412,     0.99413,     0.99414,     0.99415,     0.99416,     0.99418,     0.99419,      0.9942,     0.99421,     0.99422,     0.99424,     0.99425,     0.99426,     0.99427,     0.99428,      0.9943,     0.99431,\n","            0.99432,     0.99433,     0.99434,     0.99436,     0.99437,     0.99438,     0.99439,     0.99441,     0.99442,     0.99443,     0.99444,     0.99445,     0.99447,     0.99448,     0.99449,      0.9945,     0.99451,     0.99453,     0.99454,     0.99455,     0.99456,     0.99457,     0.99459,\n","             0.9946,     0.99461,     0.99462,     0.99463,     0.99465,     0.99466,     0.99467,     0.99468,     0.99469,     0.99471,     0.99472,     0.99473,     0.99474,     0.99475,     0.99477,     0.99478,     0.99479,      0.9948,     0.99482,     0.99483,     0.99484,     0.99485,     0.99486,\n","            0.99488,     0.99489,      0.9949,     0.99491,     0.99492,     0.99494,     0.99495,     0.99496,     0.99497,     0.99498,       0.995,     0.99501,     0.99502,     0.99503,     0.99504,     0.99506,     0.99507,     0.99508,     0.99509,      0.9951,     0.99512,     0.99513,     0.99514,\n","            0.99515,     0.99516,     0.99518,     0.99519,      0.9952,     0.99521,     0.99523,     0.99524,     0.99525,     0.99526,     0.99527,     0.99529,      0.9953,     0.99531,     0.99532,     0.99533,     0.99535,     0.99536,     0.99537,     0.99538,     0.99539,     0.99541,     0.99542,\n","            0.99543,     0.99544,     0.99545,     0.99547,     0.99548,     0.99549,      0.9955,     0.99551,     0.99553,     0.99554,     0.99555,     0.99556,     0.99557,     0.99559,      0.9956,     0.99561,     0.99562,     0.99563,     0.99565,     0.99566,     0.99567,     0.99568,     0.99569,\n","            0.99571,     0.99572,     0.99573,     0.99574,     0.99576,     0.99577,     0.99578,     0.99579,      0.9958,     0.99582,     0.99583,     0.99584,     0.99585,     0.99586,     0.99588,     0.99589,      0.9959,     0.99591,     0.99592,     0.99594,     0.99595,     0.99596,     0.99597,\n","            0.99598,       0.996,     0.99601,     0.99602,     0.99603,     0.99604,     0.99606,     0.99607,     0.99608,     0.99609,      0.9961,     0.99612,     0.99613,     0.99614,     0.99615,     0.99616,     0.99618,     0.99619,      0.9962,     0.99621,     0.99622,     0.99624,     0.99625,\n","            0.99626,     0.99627,     0.99628,      0.9963,     0.99631,     0.99632,     0.99633,     0.99634,     0.99636,     0.99637,     0.99638,     0.99639,      0.9964,     0.99642,     0.99643,     0.99644,     0.99645,     0.99646,     0.99648,     0.99649,      0.9965,     0.99651,     0.99653,\n","            0.99654,     0.99655,     0.99656,     0.99657,     0.99659,      0.9966,     0.99661,     0.99662,     0.99663,     0.99665,     0.99666,     0.99667,     0.99668,     0.99669,     0.99671,     0.99672,     0.99673,     0.99674,     0.99675,     0.99677,     0.99678,     0.99679,      0.9968,\n","            0.99681,     0.99683,     0.99684,     0.99685,     0.99686,     0.99687,     0.99689,      0.9969,     0.99691,     0.99692,     0.99693,     0.99695,     0.99696,     0.99697,     0.99698,     0.99699,     0.99701,     0.99702,     0.99703,     0.99704,     0.99705,     0.99707,     0.99708,\n","            0.99709,      0.9971,     0.99711,     0.99713,     0.99714,     0.99715,     0.99716,     0.99717,     0.99719,      0.9972,     0.99721,     0.99722,     0.99723,     0.99725,     0.99726,     0.99727,     0.99728,     0.99729,     0.99731,     0.99732,     0.99733,     0.99734,     0.99735,\n","            0.99737,     0.99738,     0.99739,      0.9974,     0.99741,     0.99743,     0.99744,     0.99745,     0.99746,     0.99747,     0.99749,      0.9975,     0.99751,     0.99752,     0.99753,     0.99755,     0.99756,     0.99757,     0.99758,     0.99759,     0.99761,     0.99762,     0.99763,\n","            0.99764,     0.99765,     0.99767,     0.99768,     0.99769,      0.9977,     0.99771,     0.99773,     0.99774,     0.99775,     0.99776,     0.99777,     0.99779,      0.9978,     0.99781,     0.99782,     0.99783,     0.99785,     0.99786,     0.99787,     0.99788,     0.99789,     0.99791,\n","            0.99792,     0.99793,     0.99794,     0.99795,     0.99797,     0.99798,     0.99799,       0.998,     0.99801,     0.99803,     0.99804,     0.99805,     0.99806,     0.99807,     0.99809,      0.9981,     0.99811,     0.99812,     0.99813,     0.99815,     0.99816,     0.99817,     0.99818,\n","            0.99819,     0.99821,     0.99822,     0.99823,     0.99824,     0.99825,     0.99826,     0.99828,     0.99829,      0.9983,     0.99831,     0.99832,     0.99834,     0.99835,     0.99836,     0.99837,     0.99838,      0.9984,     0.99841,     0.99842,     0.99843,     0.99844,     0.99846,\n","            0.99847,     0.99848,     0.99849,      0.9985,     0.99852,     0.99853,     0.99854,     0.99855,     0.99856,     0.99858,     0.99859,      0.9986,     0.99861,     0.99862,     0.99864,     0.99865,     0.99866,     0.99867,     0.99868,      0.9987,     0.99871,     0.99872,     0.99873,\n","            0.99874,     0.99876,     0.99877,     0.99878,     0.99879,      0.9988,     0.99882,     0.99883,     0.99884,     0.99885,     0.99886,     0.99888,     0.99889,      0.9989,     0.99891,     0.99892,     0.99894,     0.99895,     0.99896,     0.99897,     0.99898,       0.999,     0.99901,\n","            0.99902,     0.99903,     0.99904,     0.99905,     0.99907,     0.99908,     0.99909,      0.9991,     0.99911,     0.99913,     0.99914,     0.99915,     0.99916,     0.99917,     0.99919,      0.9992,     0.99921,     0.99922,     0.99923,     0.99925,     0.99926,     0.99927,     0.99928,\n","            0.99929,     0.99931,     0.99932,     0.99933,     0.99934,     0.99935,     0.99937,     0.99938,     0.99939,      0.9994,     0.99941,     0.99943,     0.99944,     0.99945,     0.99946,     0.99947,     0.99949,      0.9995,     0.99951,     0.99952,     0.99953,     0.99954,     0.99956,\n","            0.99957,     0.99958,     0.99959,      0.9996,     0.99962,     0.99963,     0.99964,     0.99965,     0.99966,     0.99968,     0.99969,      0.9997,     0.99971,     0.99972,     0.99974,     0.99975,     0.99976,     0.99977,     0.99978,      0.9998,     0.99981,     0.99982,     0.99983,\n","            0.99984,     0.99986,     0.99987,     0.99988,     0.99989,      0.9999,     0.99992,     0.99993,     0.99994,     0.99995,     0.99996,     0.99997,     0.99999,           1,     0.99989,     0.99977,     0.99964,     0.99952,      0.9994,     0.99927,     0.99915,     0.99903,      0.9989,\n","            0.99878,     0.99866,     0.99853,     0.99841,     0.99828,     0.99816,     0.99804,     0.99791,     0.99779,     0.99767,     0.99754,     0.99742,     0.99729,     0.99717,     0.99705,     0.99692,      0.9968,     0.99668,     0.99655,     0.99643,      0.9963,     0.99618,     0.99605,\n","            0.99593,     0.99581,     0.99568,     0.99556,     0.99543,     0.99531,     0.99518,     0.99506,     0.99494,     0.99481,     0.99469,     0.99456,     0.99444,     0.99431,     0.99419,     0.99406,     0.99394,     0.99381,     0.99369,     0.99357,     0.99344,     0.99332,     0.99319,\n","            0.99307,     0.99294,     0.99282,     0.99269,     0.99257,     0.99244,     0.99232,     0.99219,     0.99207,     0.99194,     0.99181,     0.99169,     0.99156,     0.99144,     0.99131,     0.99119,     0.99106,     0.99094,     0.99081,     0.99069,     0.99056,     0.99044,     0.99031,\n","            0.97969,     0.97887,     0.97805,     0.97723,      0.9764,     0.97557,     0.97475,     0.97392,     0.97309,     0.97225,     0.97142,     0.97058,     0.96967,     0.96872,     0.96777,     0.96681,     0.96585,      0.9649,     0.96393,     0.96297,     0.96201,     0.96104,     0.96007,\n","            0.94894,     0.94765,     0.94637,     0.94508,     0.94379,     0.94249,     0.94119,     0.93989,     0.92456,     0.91413,     0.91024,     0.90633,     0.86344,     0.85325,     0.84804,     0.84028,     0.82963,     0.82421,     0.81873,       0.817,     0.81569,     0.81437,     0.81305,\n","            0.81172,      0.8104,     0.80907,     0.80773,      0.8064,     0.80506,     0.79995,     0.79282,     0.78957,     0.78796,     0.78635,     0.78473,     0.78311,     0.78149,     0.77986,     0.77823,     0.77659,     0.72823,     0.72021,     0.71288,     0.70632,       0.665,     0.60908,\n","            0.60141,     0.59224,     0.52905,     0.50469,      0.4616,     0.40677,     0.37078,     0.35315,      0.2895,     0.27005,     0.13511,     0.11198,    0.077673,    0.064613,    0.054007,    0.043285,           0,           0,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.66667,     0.66667,     0.94048,     0.96931,     0.97593,     0.98114,     0.98116,     0.98118,     0.98121,     0.98123,     0.98126,     0.98128,      0.9813,     0.98133,     0.98135,     0.98138,      0.9814,     0.98142,     0.98145,     0.98147,      0.9815,     0.98152,     0.98154,\n","            0.98157,     0.98159,     0.98161,     0.98164,     0.98166,     0.98169,     0.98171,     0.98173,     0.98176,     0.98178,     0.98181,     0.98183,     0.98185,     0.98188,      0.9819,     0.98193,     0.98195,     0.98197,       0.982,     0.98202,     0.98204,     0.98207,     0.98209,\n","            0.98212,     0.98214,     0.98216,     0.98219,     0.98221,     0.98224,     0.98226,     0.98228,     0.98231,     0.98233,     0.98235,     0.98238,      0.9824,     0.98243,     0.98245,     0.98247,      0.9825,     0.98252,     0.98255,     0.98257,     0.98259,     0.98262,     0.98264,\n","            0.98267,     0.98269,     0.98271,     0.98274,     0.98276,     0.98278,     0.98281,     0.98283,     0.98286,     0.98288,      0.9829,     0.98293,     0.98295,     0.98298,       0.983,     0.98302,     0.98305,     0.98307,     0.98309,     0.98312,     0.98314,     0.98317,     0.98319,\n","            0.98321,     0.98324,     0.98326,     0.98329,     0.98331,     0.98333,     0.98336,     0.98338,     0.98341,     0.98343,     0.98345,     0.98348,      0.9835,     0.98352,     0.98355,     0.98357,      0.9836,     0.98362,     0.98364,     0.98367,     0.98369,     0.98372,     0.98374,\n","            0.98376,     0.98379,     0.98381,     0.98383,     0.98386,     0.98388,     0.98391,     0.98393,     0.98395,     0.98398,       0.984,     0.98403,     0.98405,     0.98407,      0.9841,     0.98412,     0.98415,     0.98417,     0.98419,     0.98422,     0.98424,     0.98426,     0.98429,\n","            0.98431,     0.98434,     0.98436,     0.98438,     0.98441,     0.98443,     0.98446,     0.98448,      0.9845,     0.98453,     0.98455,     0.98458,      0.9846,     0.98462,     0.98465,     0.98467,     0.98469,     0.98472,     0.98474,     0.98477,     0.98479,     0.98481,     0.98484,\n","            0.98486,     0.98489,     0.98491,     0.98493,     0.98496,     0.98498,       0.985,     0.98503,     0.98505,     0.98508,      0.9851,     0.98512,     0.98515,     0.98517,      0.9852,     0.98522,     0.98524,     0.98527,     0.98529,     0.98532,     0.98534,     0.98536,     0.98539,\n","            0.98541,     0.98543,     0.98546,     0.98548,     0.98551,     0.98553,     0.98555,     0.98558,      0.9856,     0.98563,     0.98565,     0.98567,      0.9857,     0.98572,     0.98574,     0.98577,     0.98579,     0.98582,     0.98584,     0.98586,     0.98589,     0.98591,     0.98594,\n","            0.98596,     0.98598,     0.98601,     0.98603,     0.98606,     0.98608,      0.9861,     0.98613,     0.98615,     0.98617,      0.9862,     0.98622,     0.98625,     0.98627,     0.98629,     0.98632,     0.98634,     0.98637,     0.98639,     0.98641,     0.98644,     0.98646,     0.98648,\n","            0.98651,     0.98653,     0.98656,     0.98658,      0.9866,     0.98663,     0.98665,     0.98668,      0.9867,     0.98672,     0.98675,     0.98677,      0.9868,     0.98682,     0.98684,     0.98687,     0.98689,     0.98691,     0.98694,     0.98696,     0.98699,     0.98701,     0.98703,\n","            0.98706,     0.98708,     0.98711,     0.98713,     0.98715,     0.98718,      0.9872,     0.98723,     0.98725,     0.98727,      0.9873,     0.98732,     0.98734,     0.98737,     0.98739,     0.98742,     0.98744,     0.98746,     0.98749,     0.98751,     0.98754,     0.98756,     0.98758,\n","            0.98761,     0.98763,     0.98765,     0.98768,      0.9877,     0.98773,     0.98775,     0.98777,      0.9878,     0.98782,     0.98785,     0.98787,     0.98789,     0.98792,     0.98794,     0.98797,     0.98799,     0.98801,     0.98804,     0.98806,     0.98808,     0.98811,     0.98813,\n","            0.98816,     0.98818,      0.9882,     0.98823,     0.98825,     0.98828,      0.9883,     0.98832,     0.98835,     0.98837,     0.98839,     0.98842,     0.98844,     0.98847,     0.98849,     0.98851,     0.98854,     0.98856,     0.98859,     0.98861,     0.98863,     0.98866,     0.98868,\n","            0.98871,     0.98873,     0.98875,     0.98878,      0.9888,     0.98882,     0.98885,     0.98887,      0.9889,     0.98892,     0.98894,     0.98897,     0.98899,     0.98902,     0.98904,     0.98906,     0.98909,     0.98911,     0.98913,     0.98916,     0.98918,     0.98921,     0.98923,\n","            0.98925,     0.98928,      0.9893,     0.98933,     0.98935,     0.98937,      0.9894,     0.98942,     0.98945,     0.98947,     0.98949,     0.98952,     0.98954,     0.98956,     0.98959,     0.98961,     0.98964,     0.98966,     0.98968,     0.98971,     0.98973,     0.98976,     0.98978,\n","             0.9898,     0.98983,     0.98985,     0.98988,      0.9899,     0.98992,     0.98995,     0.98997,     0.98999,     0.99002,     0.99004,     0.99007,     0.99009,     0.99011,     0.99014,     0.99016,     0.99019,     0.99021,     0.99023,     0.99026,     0.99028,      0.9903,     0.99033,\n","            0.99035,     0.99038,      0.9904,     0.99042,     0.99045,     0.99047,      0.9905,     0.99052,     0.99054,     0.99057,     0.99059,     0.99062,     0.99064,     0.99066,     0.99069,     0.99071,     0.99073,     0.99076,     0.99078,     0.99081,     0.99083,     0.99085,     0.99088,\n","             0.9909,     0.99093,     0.99095,     0.99097,       0.991,     0.99102,     0.99104,     0.99107,     0.99109,     0.99112,     0.99114,     0.99116,     0.99119,     0.99121,     0.99124,     0.99126,     0.99128,     0.99131,     0.99133,     0.99136,     0.99138,      0.9914,     0.99143,\n","            0.99145,     0.99147,      0.9915,     0.99152,     0.99155,     0.99157,     0.99159,     0.99162,     0.99164,     0.99167,     0.99169,     0.99171,     0.99174,     0.99176,     0.99178,     0.99181,     0.99183,     0.99186,     0.99188,      0.9919,     0.99193,     0.99195,     0.99198,\n","              0.992,     0.99202,     0.99205,     0.99207,      0.9921,     0.99212,     0.99214,     0.99217,     0.99219,     0.99221,     0.99224,     0.99226,     0.99229,     0.99231,     0.99233,     0.99236,     0.99238,     0.99241,     0.99243,     0.99245,     0.99248,      0.9925,     0.99253,\n","            0.99255,     0.99257,      0.9926,     0.99262,     0.99264,     0.99267,     0.99269,     0.99272,     0.99274,     0.99276,     0.99279,     0.99281,     0.99284,     0.99286,     0.99288,     0.99291,     0.99293,     0.99295,     0.99298,       0.993,     0.99303,     0.99305,     0.99307,\n","             0.9931,     0.99312,     0.99315,     0.99317,     0.99319,     0.99322,     0.99324,     0.99327,     0.99329,     0.99331,     0.99334,     0.99336,     0.99338,     0.99341,     0.99343,     0.99346,     0.99348,      0.9935,     0.99353,     0.99355,     0.99358,      0.9936,     0.99362,\n","            0.99365,     0.99367,     0.99369,     0.99372,     0.99374,     0.99377,     0.99379,     0.99381,     0.99384,     0.99386,     0.99389,     0.99391,     0.99393,     0.99396,     0.99398,     0.99401,     0.99403,     0.99405,     0.99408,      0.9941,     0.99412,     0.99415,     0.99417,\n","             0.9942,     0.99422,     0.99424,     0.99427,     0.99429,     0.99432,     0.99434,     0.99436,     0.99439,     0.99441,     0.99443,     0.99446,     0.99448,     0.99451,     0.99453,     0.99455,     0.99458,      0.9946,     0.99463,     0.99465,     0.99467,      0.9947,     0.99472,\n","            0.99475,     0.99477,     0.99479,     0.99482,     0.99484,     0.99486,     0.99489,     0.99491,     0.99494,     0.99496,     0.99498,     0.99501,     0.99503,     0.99506,     0.99508,      0.9951,     0.99513,     0.99515,     0.99518,      0.9952,     0.99522,     0.99525,     0.99527,\n","            0.99529,     0.99532,     0.99534,     0.99537,     0.99539,     0.99541,     0.99544,     0.99546,     0.99549,     0.99551,     0.99553,     0.99556,     0.99558,      0.9956,     0.99563,     0.99565,     0.99568,      0.9957,     0.99572,     0.99575,     0.99577,      0.9958,     0.99582,\n","            0.99584,     0.99587,     0.99589,     0.99592,     0.99594,     0.99596,     0.99599,     0.99601,     0.99603,     0.99606,     0.99608,     0.99611,     0.99613,     0.99615,     0.99618,      0.9962,     0.99623,     0.99625,     0.99627,      0.9963,     0.99632,     0.99634,     0.99637,\n","            0.99639,     0.99642,     0.99644,     0.99646,     0.99649,     0.99651,     0.99654,     0.99656,     0.99658,     0.99661,     0.99663,     0.99666,     0.99668,      0.9967,     0.99673,     0.99675,     0.99677,      0.9968,     0.99682,     0.99685,     0.99687,     0.99689,     0.99692,\n","            0.99694,     0.99697,     0.99699,     0.99701,     0.99704,     0.99706,     0.99708,     0.99711,     0.99713,     0.99716,     0.99718,      0.9972,     0.99723,     0.99725,     0.99728,      0.9973,     0.99732,     0.99735,     0.99737,      0.9974,     0.99742,     0.99744,     0.99747,\n","            0.99749,     0.99751,     0.99754,     0.99756,     0.99759,     0.99761,     0.99763,     0.99766,     0.99768,     0.99771,     0.99773,     0.99775,     0.99778,      0.9978,     0.99783,     0.99785,     0.99787,      0.9979,     0.99792,     0.99794,     0.99797,     0.99799,     0.99802,\n","            0.99804,     0.99806,     0.99809,     0.99811,     0.99814,     0.99816,     0.99818,     0.99821,     0.99823,     0.99825,     0.99828,      0.9983,     0.99833,     0.99835,     0.99837,      0.9984,     0.99842,     0.99845,     0.99847,     0.99849,     0.99852,     0.99854,     0.99857,\n","            0.99859,     0.99861,     0.99864,     0.99866,     0.99868,     0.99871,     0.99873,     0.99876,     0.99878,      0.9988,     0.99883,     0.99885,     0.99888,      0.9989,     0.99892,     0.99895,     0.99897,     0.99899,     0.99902,     0.99904,     0.99907,     0.99909,     0.99911,\n","            0.99914,     0.99916,     0.99919,     0.99921,     0.99923,     0.99926,     0.99928,     0.99931,     0.99933,     0.99935,     0.99938,      0.9994,     0.99942,     0.99945,     0.99947,      0.9995,     0.99952,     0.99954,     0.99957,     0.99959,     0.99962,     0.99964,     0.99966,\n","            0.99969,     0.99971,     0.99973,     0.99976,     0.99978,     0.99981,     0.99983,     0.99985,     0.99988,      0.9999,     0.99993,     0.99995,     0.99997,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,     0.99978,     0.99953,     0.99929,     0.99904,     0.99879,     0.99855,      0.9983,     0.99805,     0.99781,\n","            0.99756,     0.99731,     0.99707,     0.99682,     0.99658,     0.99633,     0.99608,     0.99584,     0.99559,     0.99534,      0.9951,     0.99485,      0.9946,     0.99436,     0.99411,     0.99387,     0.99362,     0.99337,     0.99313,     0.99288,     0.99263,     0.99239,     0.99214,\n","            0.99189,     0.99165,      0.9914,     0.99115,     0.99091,     0.99066,     0.99042,     0.99017,     0.98992,     0.98968,     0.98943,     0.98918,     0.98894,     0.98869,     0.98844,      0.9882,     0.98795,     0.98771,     0.98746,     0.98721,     0.98697,     0.98672,     0.98647,\n","            0.98623,     0.98598,     0.98573,     0.98549,     0.98524,     0.98499,     0.98475,      0.9845,     0.98426,     0.98401,     0.98376,     0.98352,     0.98327,     0.98302,     0.98278,     0.98253,     0.98228,     0.98204,     0.98179,     0.98155,      0.9813,     0.98105,     0.98081,\n","             0.9602,     0.95862,     0.95704,     0.95547,     0.95389,     0.95231,     0.95074,     0.94916,     0.94758,       0.946,     0.94443,     0.94285,     0.94113,     0.93934,     0.93755,     0.93576,     0.93396,     0.93217,     0.93038,     0.92859,      0.9268,       0.925,     0.92321,\n","            0.90283,     0.90051,      0.8982,     0.89588,     0.89356,     0.89124,     0.88892,      0.8866,     0.85971,     0.84184,     0.83527,      0.8287,      0.7597,     0.74406,     0.73617,     0.72456,     0.70886,     0.70098,     0.69309,     0.69062,     0.68874,     0.68686,     0.68499,\n","            0.68311,     0.68123,     0.67935,     0.67748,      0.6756,     0.67372,      0.6666,     0.65675,      0.6523,     0.65011,     0.64792,     0.64573,     0.64354,     0.64135,     0.63916,     0.63697,     0.63478,     0.57261,     0.56276,     0.55386,     0.54597,     0.49813,      0.4379,\n","            0.43001,      0.4207,     0.35967,     0.33752,     0.30005,     0.25531,     0.22758,     0.21444,     0.16925,      0.1561,    0.072451,    0.059309,    0.040406,    0.033385,    0.027753,    0.022121,           0,           0,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n","fitness: np.float64(0.9270650940442883)\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([    0.91952])\n","names: {0: 'Safety-Vests'}\n","nt_per_class: array([52])\n","nt_per_image: array([52])\n","results_dict: {'metrics/precision(B)': np.float64(0.9990187222127388), 'metrics/recall(B)': np.float64(1.0), 'metrics/mAP50(B)': np.float64(0.995), 'metrics/mAP50-95(B)': np.float64(0.9195167711603203), 'fitness': np.float64(0.9270650940442883)}\n","save_dir: PosixPath('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest2')\n","speed: {'preprocess': 0.15814505768984277, 'inference': 0.8375288846156519, 'loss': 0.00027998076855230745, 'postprocess': 0.9544512307706134}\n","stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n","task: 'detect'"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Evaluate `vest` Performance (Before Helmet Training):"],"metadata":{"id":"1xuKEOvw0GpI"}},{"cell_type":"code","source":["# Evaluate vest performance before helmet training\n","metrics_before = model_vest.val(split='test',\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bxbAWwo0Cvx","executionInfo":{"status":"ok","timestamp":1752494990348,"user_tz":-120,"elapsed":23180,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"cdfe405b-39c0-43a3-f812-8a1526c0c6aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.166 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.2 ms, read: 0.1Â±0.0 MB/s, size: 77.0 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/test/labels... 49 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:13<00:00,  3.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/test/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         49         49      0.999          1      0.995       0.94\n","Speed: 3.2ms preprocess, 11.3ms inference, 0.0ms loss, 9.4ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest22\u001b[0m\n"]}]},{"cell_type":"markdown","source":["##### ğŸ” Phase 2: Fine-Tune on `helmet` Dataset (with `vest` still in class list)"],"metadata":{"id":"5_6Shtd-0tjp"}},{"cell_type":"code","source":["original_path = '/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_0.2k'\n","new_path = '/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled'\n","\n","# Copy the whole dataset folder (images + labels)\n","shutil.copytree(original_path, new_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"hCn7AnI14WuX","executionInfo":{"status":"ok","timestamp":1752495840508,"user_tz":-120,"elapsed":145235,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"779b0827-b9e9-4448-8279-149de587ca9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def relabel_folder(label_folder):\n","    for filename in os.listdir(label_folder):\n","        if filename.endswith('.txt'):\n","            filepath = os.path.join(label_folder, filename)\n","            with open(filepath, 'r') as f:\n","                lines = f.readlines()\n","            new_lines = []\n","            for line in lines:\n","                parts = line.strip().split()\n","                if len(parts) > 0:\n","                    parts[0] = '1'  # class 1 = Helmet\n","                    new_lines.append(' '.join(parts) + '\\n')\n","            with open(filepath, 'w') as f:\n","                f.writelines(new_lines)\n","\n","# Relabel in all splits\n","for split in ['train', 'valid', 'test']:\n","    label_path = os.path.join(new_path, split, 'labels')\n","    relabel_folder(label_path)"],"metadata":{"id":"1HjQ5vvS4tC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["yaml_text = \"\"\"\n","path: /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled\n","\n","train: train/images\n","val: valid/images\n","test: test/images\n","\n","# âš ï¸ Class 0 is Safety-Vests (from earlier dataset)\n","# Class 1 is Helmet (relabelled here)\n","nc: 2\n","names: ['Safety-Vests', 'Helmet']\n","\"\"\"\n","\n","with open(\"/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml\", \"w\") as f:\n","    f.write(yaml_text)"],"metadata":{"id":"-MuND5o15BDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load previous model weights\n","model_helmet = YOLO('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest/weights/best.pt')"],"metadata":{"id":"hmY0Lc06080_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine-tune on helmet dataset while keeping vest in class list\n","model_helmet.train(\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml',\n","    epochs=60,\n","    imgsz=640,\n","    project='/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment',\n","    name='yolov8n_helmet'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"uFY-6frdygkC","executionInfo":{"status":"ok","timestamp":1752496235431,"user_tz":-120,"elapsed":105679,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"eebc21e7-5516-429c-801e-b420fbe0cdb4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.166 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=60, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_helmet2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=1 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n","Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 28.3Â±11.3 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<00:00, 202.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 3.9Â±2.6 ms, read: 6.2Â±6.3 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<00:00, 172.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2\u001b[0m\n","Starting training for 60 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/60      2.31G      3.018       4.84      2.454         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154    0.00148     0.0714   0.000996   0.000327\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/60      2.31G      2.248       4.23      1.856         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  7.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154    0.00674      0.279     0.0759     0.0395\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/60      2.31G      1.769      3.341      1.389         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.21it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.53      0.266      0.257      0.133\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/60      2.31G      1.688      2.424      1.275         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.35it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.563      0.427       0.43      0.215\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/60      2.31G      1.535      1.957      1.175         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.01it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.672      0.422      0.519      0.256\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/60      2.31G      1.448      1.799      1.136         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.809      0.496      0.607        0.3\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/60      2.31G      1.295      1.516      1.078         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.761       0.61      0.674      0.369\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/60      2.32G       1.32      1.458      1.078         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.823      0.643      0.743      0.405\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/60      2.34G      1.232      1.375      1.066         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.847      0.681      0.774      0.405\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/60      2.35G      1.256      1.263      1.027         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.813      0.708      0.803      0.419\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/60      2.37G      1.247      1.242      1.045         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.798       0.76      0.806      0.457\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/60      2.39G      1.211      1.155      1.036         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.878      0.746      0.834      0.488\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/60       2.4G      1.213      1.143       1.04         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.838      0.786      0.847      0.511\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/60      2.42G      1.125      1.049      1.002         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.84      0.773      0.829      0.453\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/60      2.44G      1.155      1.128      1.041         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.852      0.773      0.849      0.501\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/60      2.46G       1.15      1.009     0.9971         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.908      0.765      0.848      0.473\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/60      2.47G      1.109     0.9512     0.9867         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.04it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.858      0.773      0.864      0.495\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/60      2.49G      1.116     0.9521      1.009         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.66it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.863       0.78      0.862      0.504\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/60      2.51G      1.036       0.92       0.98         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.85it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.881      0.772      0.852      0.516\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/60      2.52G      1.106     0.9212     0.9876         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.66it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.879      0.803      0.868      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/60      2.54G      1.124     0.9225      1.012         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.895      0.766      0.859       0.52\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/60      2.56G      1.027     0.8633     0.9678         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.905      0.804      0.875      0.534\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/60      2.57G     0.9895     0.8107      0.962         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.901      0.779      0.865      0.548\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/60      2.59G      1.018     0.8399     0.9723         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.83it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.885      0.797      0.876      0.564\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/60      2.61G      1.001     0.7955     0.9629         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.88it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.911      0.796      0.865      0.534\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/60      2.63G      1.025     0.7912     0.9559         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.18it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.851      0.816      0.867      0.547\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/60      2.64G     0.9621     0.7521     0.9399         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.873      0.792      0.872      0.541\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/60      2.66G     0.9321     0.7377     0.9442         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.887      0.818      0.883      0.536\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/60      2.68G      1.033     0.8035     0.9543         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.73it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.879      0.847       0.89      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/60       2.7G     0.9779     0.7691     0.9405         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.908       0.87      0.905      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      31/60      2.71G     0.9586      0.741     0.9418         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.922      0.847      0.913      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      32/60      2.73G     0.9521     0.7335     0.9424         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.86it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.949      0.843      0.916      0.572\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      33/60      2.74G     0.9453      0.706     0.9294         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.928      0.836      0.902      0.576\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      34/60      2.76G     0.9468     0.7382     0.9399         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.934      0.833      0.904      0.573\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      35/60      2.78G     0.9324     0.7025     0.9337         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.946        0.8      0.906      0.576\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      36/60       2.8G     0.9307     0.6945     0.9341         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.934      0.827        0.9      0.579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      37/60      2.81G     0.8837     0.6569     0.9269         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.98it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.951      0.818      0.904      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      38/60      2.83G     0.8984     0.6737     0.9186         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.965      0.818      0.909      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      39/60      2.85G     0.8924     0.6641     0.9268         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.938      0.851      0.903       0.58\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      40/60      2.87G     0.8655     0.6415     0.9154         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.59it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.903      0.844      0.905      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      41/60      2.88G     0.8731     0.6357     0.9244         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.939      0.806      0.901      0.575\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      42/60       2.9G     0.8796     0.6609     0.9143         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.82it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.92      0.844      0.903      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      43/60      2.92G     0.8734     0.6209     0.8945         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.926      0.818      0.906      0.578\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      44/60      2.93G     0.8664     0.6264     0.9164         80        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.882      0.851      0.901      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      45/60      2.95G     0.8525     0.6328     0.9092         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.921      0.831      0.907      0.571\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      46/60      2.97G     0.8704      0.607     0.9005         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 11.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.90it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.962      0.818      0.903      0.578\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      47/60      2.98G     0.8081     0.5928     0.9013         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.909      0.857      0.914      0.569\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      48/60         3G     0.8322     0.6106     0.9059         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.928      0.825      0.905      0.591\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      49/60      3.02G     0.8255     0.5946     0.8947         62        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.942      0.839       0.91      0.595\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      50/60      3.04G     0.7669     0.5751     0.8818         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.13it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.909      0.844      0.908      0.582\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      51/60      3.05G     0.7955     0.6097     0.8895         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:02<00:00,  4.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.902      0.857      0.913      0.591\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      52/60      3.07G     0.7904      0.599     0.8735         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.922      0.818      0.905      0.595\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      53/60      3.09G     0.7773     0.6001     0.8759         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.95it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.926      0.799      0.899      0.595\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      54/60       3.1G     0.7544     0.5706     0.8646         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.93      0.812      0.896      0.591\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      55/60      3.12G     0.7378     0.5481     0.8762         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.47it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.939      0.799      0.899      0.588\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      56/60      3.14G     0.7376      0.531      0.865         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.863      0.859      0.899      0.591\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      57/60      3.15G     0.7243     0.5718     0.8649         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.872      0.864      0.894      0.587\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      58/60      3.17G     0.7209     0.5314     0.8769         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.952      0.805      0.895      0.591\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      59/60      3.19G      0.733     0.5499     0.8739         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00,  9.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.35it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.954      0.807      0.895      0.592\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      60/60      3.21G     0.7483     0.5588     0.8766         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  9.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.15it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.947      0.811      0.895      0.595\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","60 epochs completed in 0.026 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2/weights/last.pt, 6.2MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2/weights/best.pt, 6.2MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2/weights/best.pt...\n","Ultralytics 8.3.166 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.941      0.833      0.909      0.593\n","                Helmet         39        154      0.941      0.833      0.909      0.593\n","Speed: 0.1ms preprocess, 0.8ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([1])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x799473c8d2d0>\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n","curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,\n","            0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.99083,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,\n","            0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,\n","            0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.98305,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,\n","            0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96748,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,\n","            0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.96063,     0.95349,     0.95349,     0.95349,     0.95349,     0.95349,     0.95349,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,\n","            0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94776,     0.94203,     0.94203,     0.94203,     0.94203,\n","            0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.94203,     0.89116,     0.89116,     0.89116,     0.89116,     0.89116,     0.89116,     0.84615,\n","            0.84615,     0.84615,     0.84615,     0.84615,     0.84615,     0.84615,     0.84177,     0.84177,     0.84177,     0.84177,     0.84177,     0.84177,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,     0.82317,\n","            0.82317,     0.82317,     0.81928,     0.81928,     0.81928,     0.81928,     0.81928,     0.81928,     0.81928,     0.80117,     0.80117,     0.80117,     0.80117,     0.80117,     0.80117,     0.78857,     0.78857,     0.78857,     0.78857,     0.78857,     0.78857,     0.78857,     0.78531,\n","            0.78531,     0.78531,     0.78531,     0.78531,     0.78531,     0.59829,     0.59829,     0.59829,     0.59829,     0.59829,     0.59829,     0.59829,     0.49129,     0.49129,     0.49129,     0.49129,     0.49129,     0.49129,     0.47492,     0.47492,     0.47492,     0.47492,     0.47492,\n","            0.47492,     0.47492,     0.46429,     0.46429,     0.46429,     0.46429,     0.46429,     0.46429,     0.32877,     0.32877,     0.32877,     0.32877,     0.32877,     0.32877,     0.32877,     0.23654,     0.23654,     0.23654,     0.23654,     0.23654,     0.23654,     0.19837,     0.19837,\n","            0.19837,     0.19837,     0.19837,     0.19837,     0.19837,     0.17458,     0.17458,     0.17458,     0.17458,     0.17458,     0.17458,      0.1678,      0.1678,      0.1678,      0.1678,      0.1678,      0.1678,      0.1678,    0.090578,    0.090578,    0.090578,    0.090578,    0.090578,\n","           0.090578,    0.045203,    0.043791,    0.042378,    0.040966,    0.039553,     0.03814,    0.036728,    0.035315,    0.033903,     0.03249,    0.031077,    0.029665,    0.028252,     0.02684,    0.025427,    0.024014,    0.022602,    0.021189,    0.019776,    0.018364,    0.016951,    0.015539,\n","           0.014126,    0.012713,    0.011301,   0.0098882,   0.0084756,    0.007063,   0.0056504,   0.0042378,   0.0028252,   0.0014126,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.087493,    0.087493,     0.23287,     0.29854,     0.35063,       0.388,     0.43116,     0.46296,     0.48812,     0.50326,     0.52095,     0.53789,     0.56086,     0.57234,     0.58674,     0.60305,      0.6124,     0.61653,     0.62395,     0.62442,     0.62788,     0.63567,     0.64055,\n","            0.65076,     0.65554,     0.66562,     0.67131,     0.67857,     0.68638,     0.69492,     0.69735,     0.70355,     0.70988,     0.71301,     0.71397,     0.71618,     0.71869,     0.72044,     0.72209,     0.72338,     0.72496,     0.72837,     0.73185,     0.73371,     0.73432,     0.73494,\n","            0.73769,      0.7393,     0.74063,     0.74196,     0.74332,     0.74495,     0.74855,     0.75348,      0.7539,     0.75432,     0.75474,     0.75516,     0.75815,     0.76198,     0.76603,     0.76709,     0.76836,     0.77048,       0.772,     0.77537,     0.77682,      0.7782,     0.77902,\n","            0.77952,     0.78002,     0.78052,       0.783,     0.78378,     0.78446,     0.78515,     0.78599,     0.78688,     0.79019,     0.79179,     0.79549,     0.79746,     0.79941,     0.80172,     0.80392,     0.80451,      0.8051,     0.80568,     0.80655,     0.80749,     0.80933,     0.81173,\n","            0.81324,      0.8143,      0.8153,      0.8158,     0.81631,     0.81681,     0.81732,     0.81791,     0.81867,     0.81943,     0.82022,     0.82117,     0.82212,     0.82503,     0.82547,     0.82591,     0.82635,     0.82679,     0.82722,     0.82874,     0.83063,     0.83226,     0.83334,\n","            0.83439,     0.83534,     0.83622,      0.8371,     0.83798,     0.83886,     0.83974,     0.83944,     0.83892,      0.8384,     0.83788,     0.83736,     0.83684,     0.83659,     0.83875,     0.83804,     0.83733,     0.83663,     0.83592,     0.83603,     0.83987,     0.84121,     0.84203,\n","            0.84284,     0.84178,     0.83995,     0.83978,     0.84014,      0.8405,     0.84087,     0.84123,     0.84159,     0.84195,     0.84271,     0.84378,      0.8454,     0.84768,      0.8482,     0.84872,     0.84923,     0.84975,     0.84655,     0.84844,     0.84729,     0.84615,     0.84537,\n","            0.84522,     0.84507,     0.84492,     0.84477,     0.84462,     0.84447,     0.84432,     0.84417,     0.84402,     0.84387,     0.84372,     0.84357,     0.84342,     0.84328,     0.84313,     0.84298,     0.84283,     0.84268,     0.84253,     0.84238,     0.84223,     0.84208,     0.84193,\n","            0.84178,     0.84251,     0.84327,     0.84403,     0.84464,      0.8451,     0.84555,       0.846,     0.84645,      0.8469,     0.84723,     0.84744,     0.84764,     0.84785,     0.84805,     0.84826,     0.84847,     0.84867,     0.84888,     0.84908,     0.84929,     0.84949,      0.8497,\n","            0.84992,     0.85018,     0.85045,     0.85071,     0.85097,     0.85123,      0.8515,     0.85176,     0.85202,     0.85228,     0.85255,     0.85156,     0.85048,      0.8494,      0.8512,       0.851,     0.85032,     0.84965,     0.84897,     0.84829,     0.84806,     0.84846,     0.84886,\n","            0.84925,     0.84965,     0.85004,     0.85044,     0.85103,     0.85184,     0.85265,     0.85363,     0.85683,     0.85875,     0.85939,     0.85983,     0.86027,     0.86071,     0.86114,     0.86158,     0.86338,     0.86474,     0.86483,     0.86491,       0.865,     0.86508,     0.86517,\n","            0.86525,     0.86534,     0.86542,      0.8655,     0.86559,     0.86567,     0.86576,     0.86584,     0.86593,     0.86601,      0.8661,     0.86618,     0.86627,     0.86635,     0.86643,     0.86652,      0.8666,     0.86669,     0.86677,     0.86686,     0.86694,     0.86702,     0.86711,\n","            0.86719,     0.86728,     0.86736,     0.86745,     0.86753,     0.86773,     0.86798,     0.86822,     0.86846,      0.8687,     0.86894,     0.86918,     0.86942,     0.86966,     0.86991,     0.87015,     0.87039,     0.86672,     0.86679,     0.86686,     0.86692,     0.86699,     0.86706,\n","            0.86713,      0.8672,     0.86726,     0.86733,      0.8674,     0.86747,     0.86753,      0.8676,     0.86767,     0.86774,      0.8678,     0.86787,     0.86794,     0.86801,     0.86807,     0.86814,     0.86821,     0.86828,     0.86834,     0.86841,     0.86848,     0.86855,     0.86861,\n","            0.86868,     0.86875,     0.86882,     0.86888,     0.86895,     0.86902,     0.86909,     0.86915,     0.86922,     0.86929,     0.86936,     0.86942,     0.86949,     0.86956,     0.87222,     0.87277,     0.87308,     0.87338,     0.87369,       0.874,     0.87431,     0.87462,     0.87493,\n","            0.87524,     0.87559,     0.87601,     0.87643,     0.87684,     0.87726,     0.87768,      0.8781,     0.87888,      0.8804,     0.88161,      0.8823,     0.88298,     0.88366,     0.88434,      0.8861,     0.88743,     0.88762,     0.88782,     0.88801,     0.88821,      0.8884,      0.8886,\n","            0.88879,     0.88899,     0.88918,     0.88938,     0.88957,     0.88976,     0.88996,     0.89015,     0.89035,     0.88994,     0.88923,     0.88852,     0.88781,      0.8871,     0.88642,     0.88584,     0.88526,     0.88468,     0.88409,     0.88351,     0.88292,     0.88238,     0.88185,\n","            0.88133,      0.8808,     0.88027,     0.87974,     0.87921,     0.87901,      0.8793,     0.87959,     0.87988,     0.88018,     0.88047,     0.88076,     0.88105,     0.88134,     0.88163,     0.88192,      0.8818,     0.88164,     0.88149,     0.88133,     0.88117,     0.88101,     0.88085,\n","             0.8807,     0.88054,     0.88038,     0.88022,     0.88006,     0.87991,     0.87975,     0.87959,     0.87943,     0.87927,     0.87911,     0.87896,      0.8788,     0.87864,     0.87848,     0.87832,     0.87816,     0.87749,     0.87548,     0.87377,      0.8727,     0.87162,     0.87053,\n","            0.86995,     0.86961,     0.86927,     0.86893,     0.86859,     0.86825,     0.86791,     0.86757,     0.86723,     0.86689,     0.86655,     0.86621,     0.86638,     0.86657,     0.86675,     0.86694,     0.86713,     0.86732,      0.8675,     0.86769,     0.86788,     0.86807,     0.86825,\n","            0.86844,     0.86863,     0.86881,       0.869,     0.86919,     0.86798,     0.86593,     0.86567,     0.86631,     0.86694,     0.86757,      0.8682,     0.86796,      0.8675,     0.86705,     0.86659,     0.86612,     0.86566,      0.8652,     0.86474,     0.86428,     0.86413,     0.86398,\n","            0.86382,     0.86367,     0.86351,     0.86336,      0.8632,     0.86305,      0.8629,     0.86274,     0.86259,     0.86243,     0.86228,     0.86212,     0.86197,     0.86181,     0.86166,     0.86151,     0.86135,      0.8612,     0.86104,     0.86089,     0.86073,     0.86058,     0.86042,\n","            0.86027,     0.85928,     0.85788,     0.85647,     0.85626,     0.85646,     0.85666,     0.85686,     0.85706,     0.85726,     0.85745,     0.85765,     0.85785,     0.85805,     0.85825,     0.85844,     0.85864,     0.85884,     0.85904,     0.85911,     0.85841,      0.8577,       0.857,\n","            0.85629,     0.85558,     0.85492,     0.85439,     0.85386,     0.85333,     0.85279,     0.85226,     0.85172,     0.85119,      0.8504,     0.84933,     0.84825,     0.84717,     0.84687,     0.84713,      0.8474,     0.84767,     0.84793,      0.8482,     0.84846,     0.84873,     0.84899,\n","            0.84925,     0.84952,     0.84978,     0.84996,     0.85012,     0.85029,     0.85045,     0.85062,     0.85078,     0.85095,     0.85111,     0.85128,     0.85144,     0.85161,     0.85177,     0.85193,      0.8521,     0.85226,     0.85242,     0.85259,     0.85275,     0.85292,     0.85277,\n","            0.85257,     0.85237,     0.85217,     0.85197,     0.85177,     0.85156,     0.85136,     0.85116,     0.85096,     0.85076,     0.85055,     0.85035,     0.85015,     0.84995,     0.84975,     0.84954,     0.84934,     0.84914,     0.84894,     0.84874,     0.84492,     0.84357,      0.8426,\n","            0.84162,     0.84064,     0.83959,     0.83849,     0.83738,     0.83627,     0.83069,     0.82941,     0.82812,     0.82665,     0.82438,     0.82257,     0.82228,     0.82198,     0.82169,      0.8214,      0.8211,     0.82081,     0.82051,     0.82022,     0.81992,     0.81963,     0.81933,\n","            0.81904,     0.81874,     0.81844,     0.81823,     0.81866,     0.81908,     0.81951,     0.81993,     0.82036,     0.82078,     0.82121,     0.81885,     0.81641,     0.81525,     0.81409,     0.81292,     0.81197,     0.81131,     0.81064,     0.80997,      0.8093,     0.80863,     0.80796,\n","            0.80271,     0.80208,     0.80144,     0.80081,     0.80018,     0.79954,     0.79891,     0.80141,     0.80087,     0.80034,     0.79981,     0.79928,     0.79874,     0.79821,     0.79768,     0.79714,     0.79643,     0.79556,     0.79468,      0.7938,     0.79292,     0.79202,     0.79105,\n","            0.79008,      0.7891,     0.78813,     0.78197,     0.77949,     0.77734,     0.77592,     0.77449,     0.77306,     0.77163,     0.77019,     0.76875,     0.76638,     0.76303,     0.76157,     0.76011,     0.75865,     0.75718,     0.75571,     0.75424,     0.74769,     0.74619,      0.7447,\n","             0.7432,     0.74204,     0.74099,     0.73993,     0.73888,     0.73782,     0.73183,     0.73106,      0.7303,     0.72953,     0.72876,     0.72799,     0.72715,     0.72535,     0.72355,     0.72161,     0.71889,      0.7106,      0.7069,     0.70574,     0.70553,     0.70533,     0.70513,\n","            0.70492,     0.70472,     0.70452,     0.70431,     0.70411,     0.70391,     0.70371,      0.7035,      0.7033,     0.70309,     0.70289,     0.70269,     0.70248,     0.70228,     0.70208,     0.70187,     0.70167,     0.70146,     0.70126,     0.70106,     0.70085,     0.70065,     0.70044,\n","            0.69706,     0.69328,     0.68948,     0.68751,      0.6856,     0.68368,     0.68175,     0.67982,       0.678,     0.67703,     0.67606,     0.67508,     0.67411,     0.67313,     0.67216,     0.67118,      0.6702,     0.66922,     0.66823,     0.66725,     0.66505,     0.66109,     0.66021,\n","             0.6595,      0.6588,     0.65809,     0.65739,     0.65668,     0.65598,     0.65527,     0.65463,     0.65403,     0.65342,     0.65282,     0.65221,     0.65161,       0.651,      0.6504,     0.64979,     0.64919,      0.6473,     0.64527,     0.64323,     0.64168,     0.64015,     0.63861,\n","             0.6371,     0.63615,      0.6352,     0.63424,     0.63329,     0.63233,     0.63137,     0.62195,     0.61772,     0.61347,     0.60576,     0.60504,     0.60432,      0.6036,     0.60288,     0.60216,     0.60143,     0.60071,     0.59996,      0.5981,     0.59623,     0.59435,     0.58675,\n","            0.58609,     0.58542,     0.58476,     0.58409,     0.58342,     0.58275,     0.58209,     0.58142,     0.58075,     0.57836,     0.57567,     0.56682,      0.5653,     0.56377,     0.56225,     0.56066,     0.55604,     0.55011,     0.54626,      0.5447,     0.54313,     0.54156,     0.53998,\n","            0.53841,     0.53682,     0.53524,     0.53365,     0.53104,     0.52816,      0.5237,     0.49726,     0.49646,     0.49567,     0.49488,     0.49408,     0.49329,     0.49249,      0.4917,      0.4909,      0.4825,     0.48031,     0.47811,      0.4759,     0.45722,     0.45325,     0.44624,\n","            0.43338,     0.42929,     0.42176,     0.41342,      0.4109,     0.40922,     0.40753,     0.40584,     0.40415,     0.39012,     0.38281,     0.37651,     0.37211,     0.36903,     0.36681,     0.36459,     0.36236,     0.35099,     0.34189,     0.33459,     0.33254,     0.33048,     0.32841,\n","            0.32635,     0.32282,     0.31906,     0.31603,     0.31393,     0.31182,     0.30971,     0.30682,       0.297,     0.29458,     0.29216,     0.28973,     0.28791,      0.2864,      0.2849,     0.28339,     0.28188,     0.28037,     0.27809,     0.27413,     0.27016,     0.25793,     0.25287,\n","            0.24703,     0.24018,     0.23857,     0.23709,     0.23561,     0.23413,     0.23265,     0.23116,     0.22838,     0.21876,     0.21347,     0.20913,     0.20834,     0.20755,     0.20676,     0.20596,     0.20517,     0.20437,     0.20358,     0.20278,     0.20199,     0.20119,     0.20039,\n","            0.19959,     0.19863,      0.1943,     0.18995,     0.18602,     0.18236,     0.17869,     0.16233,     0.14134,     0.13673,     0.13179,     0.12596,     0.11948,      0.1116,      0.1084,     0.10602,     0.10363,     0.10123,    0.098828,    0.096419,    0.094004,    0.091583,    0.089156,\n","           0.074703,    0.071614,    0.068515,    0.065407,    0.058039,    0.046158,    0.039785,      0.0375,     0.03655,    0.035599,    0.034648,    0.033695,    0.032741,    0.031787,    0.030831,    0.029875,    0.028918,     0.02796,       0.027,     0.02604,    0.024377,    0.022209,    0.020037,\n","            0.01786,    0.015679,    0.013492,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.045818,    0.045818,     0.13249,     0.17716,     0.21542,     0.24479,     0.28018,     0.30764,     0.33108,     0.34517,     0.36203,      0.3786,     0.40177,     0.41365,     0.42886,     0.44652,     0.45685,     0.46308,      0.4715,     0.47376,     0.47775,     0.48683,     0.49448,\n","            0.50676,     0.51258,     0.52501,     0.53212,     0.54131,     0.55132,     0.56243,     0.56562,     0.57382,     0.58229,     0.58651,     0.58781,     0.59081,     0.59423,     0.59946,     0.60176,     0.60354,     0.60575,     0.61052,     0.61543,     0.61806,     0.61894,     0.61981,\n","            0.62373,     0.62603,     0.62794,     0.62987,     0.63182,     0.63419,     0.63942,     0.64665,     0.64727,     0.64789,     0.64851,     0.64913,     0.65356,     0.65927,     0.66536,     0.66695,     0.66888,      0.6721,     0.67442,     0.67958,     0.68181,     0.68393,     0.68521,\n","            0.68598,     0.68675,     0.68753,      0.6914,      0.6926,     0.69367,     0.69474,     0.69606,     0.69746,     0.70268,     0.70522,      0.7111,     0.71426,     0.71739,     0.72113,      0.7247,     0.72565,     0.72661,     0.72756,     0.72899,     0.73052,     0.73353,     0.73748,\n","            0.73999,     0.74174,      0.7434,     0.74424,     0.74508,     0.74592,     0.74676,     0.74775,     0.74902,      0.7503,     0.75163,     0.75322,     0.75482,     0.75975,     0.76049,     0.76123,     0.76198,     0.76272,     0.76347,     0.76606,     0.76929,     0.77209,     0.77395,\n","            0.77577,     0.77741,     0.77894,     0.78046,     0.78199,     0.78353,     0.78507,     0.78516,     0.78498,      0.7848,     0.78462,     0.78444,     0.78426,     0.78449,     0.78852,     0.78827,     0.78803,     0.78779,     0.78755,     0.78854,     0.79539,     0.79781,     0.79928,\n","            0.80074,     0.80074,     0.80014,      0.8005,     0.80116,     0.80182,     0.80247,     0.80313,     0.80379,     0.80445,     0.80584,     0.80781,     0.81077,     0.81498,     0.81594,      0.8169,     0.81786,     0.81881,     0.81847,     0.82299,     0.82264,      0.8223,     0.82207,\n","            0.82202,     0.82198,     0.82193,     0.82189,     0.82184,      0.8218,     0.82175,     0.82171,     0.82166,     0.82162,     0.82157,     0.82153,     0.82148,     0.82144,     0.82139,     0.82135,      0.8213,     0.82126,     0.82121,     0.82117,     0.82112,     0.82108,     0.82103,\n","            0.82099,      0.8224,     0.82384,     0.82528,     0.82647,     0.82733,      0.8282,     0.82906,     0.82993,     0.83079,     0.83144,     0.83183,     0.83223,     0.83263,     0.83302,     0.83342,     0.83382,     0.83421,     0.83461,     0.83501,     0.83541,      0.8358,      0.8362,\n","            0.83663,     0.83714,     0.83765,     0.83816,     0.83867,     0.83918,     0.83969,     0.84021,     0.84072,     0.84123,     0.84174,      0.8415,      0.8412,     0.84091,     0.84534,     0.84599,     0.84581,     0.84563,     0.84545,     0.84527,     0.84549,     0.84628,     0.84707,\n","            0.84786,     0.84865,     0.84944,     0.85023,     0.85141,     0.85304,     0.85467,     0.85663,      0.8631,       0.867,     0.86832,     0.86921,     0.87011,       0.871,      0.8719,     0.87279,     0.87651,     0.87931,     0.87949,     0.87966,     0.87984,     0.88001,     0.88019,\n","            0.88036,     0.88054,     0.88071,     0.88089,     0.88106,     0.88124,     0.88141,     0.88159,     0.88176,     0.88194,     0.88211,     0.88229,     0.88247,     0.88264,     0.88282,     0.88299,     0.88317,     0.88334,     0.88352,     0.88369,     0.88387,     0.88404,     0.88422,\n","            0.88439,     0.88457,     0.88474,     0.88492,     0.88509,     0.88552,     0.88602,     0.88653,     0.88703,     0.88753,     0.88804,     0.88854,     0.88905,     0.88955,     0.89005,     0.89056,     0.89106,     0.89053,     0.89067,     0.89081,     0.89096,      0.8911,     0.89124,\n","            0.89139,     0.89153,     0.89167,     0.89181,     0.89196,      0.8921,     0.89224,     0.89239,     0.89253,     0.89267,     0.89282,     0.89296,      0.8931,     0.89325,     0.89339,     0.89353,     0.89367,     0.89382,     0.89396,      0.8941,     0.89425,     0.89439,     0.89453,\n","            0.89468,     0.89482,     0.89496,      0.8951,     0.89525,     0.89539,     0.89553,     0.89568,     0.89582,     0.89596,     0.89611,     0.89625,     0.89639,     0.89654,     0.90221,     0.90338,     0.90405,     0.90471,     0.90537,     0.90604,      0.9067,     0.90736,     0.90803,\n","            0.90869,     0.90945,     0.91036,     0.91126,     0.91217,     0.91307,     0.91398,     0.91488,     0.91658,      0.9199,     0.92255,     0.92405,     0.92555,     0.92705,     0.92855,     0.93242,     0.93537,     0.93581,     0.93624,     0.93667,     0.93711,     0.93754,     0.93798,\n","            0.93841,     0.93885,     0.93928,     0.93971,     0.94015,     0.94058,     0.94102,     0.94145,     0.94188,     0.94198,      0.9419,     0.94182,     0.94174,     0.94166,     0.94159,     0.94152,     0.94146,     0.94139,     0.94133,     0.94126,     0.94119,     0.94113,     0.94107,\n","            0.94101,     0.94096,      0.9409,     0.94084,     0.94078,     0.94101,     0.94168,     0.94235,     0.94302,     0.94369,     0.94436,     0.94502,     0.94569,     0.94636,     0.94703,      0.9477,     0.94775,     0.94773,     0.94771,      0.9477,     0.94768,     0.94767,     0.94765,\n","            0.94764,     0.94762,      0.9476,     0.94759,     0.94757,     0.94756,     0.94754,     0.94752,     0.94751,     0.94749,     0.94748,     0.94746,     0.94744,     0.94743,     0.94741,      0.9474,     0.94738,     0.94731,     0.94711,     0.94693,     0.94682,     0.94671,      0.9466,\n","            0.94654,     0.94651,     0.94647,     0.94644,      0.9464,     0.94637,     0.94633,      0.9463,     0.94626,     0.94623,     0.94619,     0.94616,     0.94659,     0.94703,     0.94748,     0.94793,     0.94838,     0.94883,     0.94928,     0.94973,     0.95018,     0.95063,     0.95107,\n","            0.95152,     0.95197,     0.95242,     0.95287,     0.95332,     0.95337,     0.95319,     0.95416,     0.95569,     0.95723,     0.95877,     0.96031,      0.9606,     0.96057,     0.96053,     0.96049,     0.96046,     0.96042,     0.96039,     0.96035,     0.96032,     0.96031,     0.96029,\n","            0.96028,     0.96027,     0.96026,     0.96025,     0.96023,     0.96022,     0.96021,      0.9602,     0.96018,     0.96017,     0.96016,     0.96015,     0.96014,     0.96012,     0.96011,      0.9601,     0.96009,     0.96008,     0.96006,     0.96005,     0.96004,     0.96003,     0.96002,\n","               0.96,     0.95993,     0.95982,     0.95971,     0.96005,     0.96055,     0.96105,     0.96155,     0.96205,     0.96255,     0.96305,     0.96355,     0.96405,     0.96455,     0.96505,     0.96555,     0.96605,     0.96655,     0.96705,     0.96747,     0.96743,     0.96738,     0.96734,\n","            0.96729,     0.96725,      0.9672,     0.96717,     0.96713,      0.9671,     0.96706,     0.96703,       0.967,     0.96696,     0.96691,     0.96684,     0.96677,      0.9667,     0.96707,     0.96776,     0.96845,     0.96915,     0.96984,     0.97053,     0.97123,     0.97192,     0.97262,\n","            0.97331,       0.974,      0.9747,     0.97517,      0.9756,     0.97603,     0.97647,      0.9769,     0.97734,     0.97777,     0.97821,     0.97864,     0.97907,     0.97951,     0.97994,     0.98038,     0.98081,     0.98125,     0.98168,     0.98211,     0.98255,     0.98298,     0.98305,\n","            0.98304,     0.98303,     0.98302,     0.98302,     0.98301,       0.983,       0.983,     0.98299,     0.98298,     0.98298,     0.98297,     0.98296,     0.98296,     0.98295,     0.98294,     0.98293,     0.98293,     0.98292,     0.98291,     0.98291,     0.98277,     0.98273,     0.98269,\n","            0.98266,     0.98263,     0.98259,     0.98255,     0.98251,     0.98247,     0.98227,     0.98223,     0.98218,     0.98213,     0.98205,     0.98198,     0.98197,     0.98196,     0.98195,     0.98194,     0.98193,     0.98191,      0.9819,     0.98189,     0.98188,     0.98187,     0.98186,\n","            0.98185,     0.98184,     0.98183,     0.98196,     0.98319,     0.98442,     0.98565,     0.98688,     0.98811,     0.98934,     0.99057,     0.99078,     0.99073,     0.99071,     0.99069,     0.99067,     0.99065,     0.99064,     0.99062,     0.99061,      0.9906,     0.99058,     0.99057,\n","            0.99047,     0.99046,     0.99044,     0.99043,     0.99042,     0.99041,     0.99039,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.96753,     0.96753,     0.96104,     0.94805,     0.94156,     0.93506,     0.93506,     0.93506,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92857,     0.92208,     0.92208,     0.91558,     0.91558,     0.91558,     0.90909,\n","            0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,     0.90909,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,\n","             0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,\n","             0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,\n","             0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,\n","             0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,      0.9026,     0.90179,     0.90083,     0.89987,     0.89891,     0.89795,     0.89699,      0.8961,     0.89581,     0.89452,     0.89322,     0.89192,     0.89062,     0.88961,     0.88961,     0.88961,     0.88961,\n","            0.88961,     0.88725,     0.88392,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.88312,     0.87662,     0.87552,     0.87347,     0.87142,     0.87003,\n","            0.86977,      0.8695,     0.86923,     0.86897,      0.8687,     0.86843,     0.86817,      0.8679,     0.86764,     0.86737,      0.8671,     0.86684,     0.86657,      0.8663,     0.86604,     0.86577,     0.86551,     0.86524,     0.86497,     0.86471,     0.86444,     0.86417,     0.86391,\n","            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,\n","            0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86364,     0.86186,     0.85996,     0.85806,     0.85714,     0.85607,     0.85489,      0.8537,     0.85252,     0.85134,     0.85065,     0.85065,     0.85065,\n","            0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,\n","            0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,\n","            0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.85065,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,\n","            0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,\n","            0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,\n","            0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,\n","            0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84416,     0.84335,     0.84214,     0.84093,     0.83972,     0.83851,     0.83736,     0.83638,     0.83539,     0.83441,     0.83342,     0.83243,     0.83145,     0.83053,     0.82965,\n","            0.82876,     0.82787,     0.82698,      0.8261,     0.82521,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82468,     0.82443,     0.82417,     0.82391,     0.82364,     0.82338,     0.82312,     0.82285,\n","            0.82259,     0.82233,     0.82206,      0.8218,     0.82154,     0.82127,     0.82101,     0.82074,     0.82048,     0.82022,     0.81995,     0.81969,     0.81943,     0.81916,      0.8189,     0.81864,     0.81837,     0.81725,     0.81393,     0.81111,     0.80933,     0.80756,     0.80578,\n","            0.80482,     0.80427,     0.80371,     0.80316,      0.8026,     0.80205,      0.8015,     0.80094,     0.80039,     0.79983,     0.79928,     0.79872,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,      0.7987,\n","             0.7987,      0.7987,      0.7987,      0.7987,      0.7987,     0.79663,     0.79331,     0.79221,     0.79221,     0.79221,     0.79221,     0.79221,     0.79162,     0.79088,     0.79014,      0.7894,     0.78866,     0.78792,     0.78718,     0.78645,     0.78571,     0.78546,     0.78522,\n","            0.78497,     0.78473,     0.78448,     0.78423,     0.78399,     0.78374,     0.78349,     0.78325,       0.783,     0.78275,     0.78251,     0.78226,     0.78201,     0.78177,     0.78152,     0.78127,     0.78103,     0.78078,     0.78053,     0.78029,     0.78004,     0.77979,     0.77955,\n","             0.7793,     0.77773,     0.77551,     0.77329,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77273,     0.77258,     0.77147,     0.77036,     0.76925,\n","            0.76814,     0.76703,       0.766,     0.76517,     0.76434,      0.7635,     0.76267,     0.76184,     0.76101,     0.76018,     0.75895,     0.75728,     0.75562,     0.75396,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,\n","            0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75325,     0.75299,\n","            0.75268,     0.75237,     0.75206,     0.75175,     0.75144,     0.75113,     0.75082,     0.75051,      0.7502,     0.74989,     0.74958,     0.74927,     0.74896,     0.74865,     0.74834,     0.74803,     0.74772,     0.74741,      0.7471,     0.74679,     0.74097,     0.73894,     0.73746,\n","            0.73598,      0.7345,     0.73293,     0.73127,      0.7296,     0.72794,     0.71964,     0.71774,     0.71583,     0.71367,     0.71034,     0.70769,     0.70726,     0.70683,      0.7064,     0.70597,     0.70554,     0.70512,     0.70469,     0.70426,     0.70383,      0.7034,     0.70297,\n","            0.70254,     0.70211,     0.70168,      0.7013,      0.7013,      0.7013,      0.7013,      0.7013,      0.7013,      0.7013,      0.7013,     0.69777,     0.69425,     0.69259,     0.69092,     0.68926,      0.6879,     0.68695,       0.686,     0.68505,      0.6841,     0.68315,      0.6822,\n","            0.67479,      0.6739,     0.67302,     0.67213,     0.67124,     0.67035,     0.66947,     0.66862,     0.66788,     0.66714,      0.6664,     0.66566,     0.66492,     0.66418,     0.66344,      0.6627,     0.66173,     0.66052,     0.65931,      0.6581,     0.65689,     0.65566,     0.65433,\n","              0.653,     0.65167,     0.65034,     0.64199,     0.63866,     0.63578,     0.63387,     0.63197,     0.63007,     0.62817,     0.62627,     0.62437,     0.62125,     0.61685,     0.61495,     0.61305,     0.61115,     0.60924,     0.60734,     0.60544,     0.59705,     0.59514,     0.59324,\n","            0.59134,     0.58988,     0.58855,     0.58722,     0.58589,     0.58456,     0.57707,     0.57612,     0.57517,     0.57422,     0.57327,     0.57232,     0.57128,     0.56906,     0.56684,     0.56447,     0.56114,     0.55111,     0.54668,     0.54528,     0.54504,      0.5448,     0.54455,\n","            0.54431,     0.54407,     0.54383,     0.54358,     0.54334,      0.5431,     0.54286,     0.54262,     0.54237,     0.54213,     0.54189,     0.54165,     0.54141,     0.54116,     0.54092,     0.54068,     0.54044,      0.5402,     0.53995,     0.53971,     0.53947,     0.53923,     0.53899,\n","            0.53499,     0.53055,     0.52611,     0.52382,      0.5216,     0.51939,     0.51717,     0.51495,     0.51286,     0.51175,     0.51064,     0.50953,     0.50842,     0.50731,      0.5062,     0.50509,     0.50398,     0.50287,     0.50177,     0.50066,     0.49819,     0.49375,     0.49277,\n","            0.49198,      0.4912,     0.49042,     0.48963,     0.48885,     0.48807,     0.48728,     0.48658,     0.48591,     0.48525,     0.48458,     0.48392,     0.48325,     0.48258,     0.48192,     0.48125,     0.48059,     0.47853,     0.47631,     0.47409,     0.47241,     0.47075,     0.46908,\n","            0.46746,     0.46644,     0.46541,     0.46439,     0.46337,     0.46234,     0.46132,     0.45132,     0.44688,     0.44245,     0.43447,     0.43373,     0.43299,     0.43225,     0.43152,     0.43078,     0.43004,      0.4293,     0.42853,     0.42663,     0.42473,     0.42283,     0.41518,\n","            0.41452,     0.41385,     0.41318,     0.41252,     0.41185,     0.41119,     0.41052,     0.40986,     0.40919,     0.40683,     0.40417,      0.3955,     0.39402,     0.39254,     0.39106,     0.38952,     0.38508,     0.37941,     0.37576,     0.37428,     0.37281,     0.37133,     0.36985,\n","            0.36837,     0.36689,     0.36541,     0.36393,      0.3615,     0.35884,     0.35473,      0.3309,      0.3302,      0.3295,      0.3288,      0.3281,      0.3274,     0.32669,     0.32599,     0.32529,     0.31796,     0.31606,     0.31415,     0.31225,     0.29636,     0.29303,      0.2872,\n","            0.27664,     0.27331,     0.26723,     0.26058,     0.25858,     0.25724,     0.25591,     0.25458,     0.25325,     0.24233,     0.23671,     0.23191,     0.22858,     0.22626,      0.2246,     0.22294,     0.22127,     0.21285,     0.20619,     0.20091,     0.19943,     0.19795,     0.19647,\n","            0.19499,     0.19248,     0.18981,     0.18767,     0.18619,     0.18471,     0.18323,     0.18121,      0.1744,     0.17273,     0.17107,      0.1694,     0.16816,     0.16714,     0.16611,     0.16509,     0.16406,     0.16304,      0.1615,     0.15884,     0.15618,     0.14806,     0.14473,\n","            0.14092,     0.13648,     0.13544,     0.13449,     0.13354,     0.13259,     0.13163,     0.13068,     0.12891,     0.12282,     0.11949,     0.11678,     0.11628,     0.11579,      0.1153,      0.1148,     0.11431,     0.11382,     0.11332,     0.11283,     0.11234,     0.11185,     0.11135,\n","            0.11086,     0.11026,      0.1076,     0.10494,     0.10255,     0.10033,     0.09811,    0.088335,    0.076044,    0.073381,    0.070541,    0.067213,    0.063535,    0.059098,    0.057307,    0.055976,    0.054645,    0.053314,    0.051983,    0.050651,     0.04932,    0.047989,    0.046658,\n","           0.038801,    0.037137,    0.035473,    0.033809,    0.029887,    0.023624,    0.020296,    0.019108,    0.018615,    0.018122,    0.017629,    0.017136,    0.016643,     0.01615,    0.015657,    0.015164,    0.014671,    0.014178,    0.013685,    0.013192,    0.012339,    0.011229,     0.01012,\n","          0.0090106,   0.0079013,    0.006792,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n","fitness: np.float64(0.6247224761998967)\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([    0.59317,     0.59317])\n","names: {0: 'Safety-Vests', 1: 'Helmet'}\n","nt_per_class: array([  0, 154])\n","nt_per_image: array([ 0, 39])\n","results_dict: {'metrics/precision(B)': np.float64(0.9413253400976633), 'metrics/recall(B)': np.float64(0.8334202408276483), 'metrics/mAP50(B)': np.float64(0.908699470242782), 'metrics/mAP50-95(B)': np.float64(0.5931694768617983), 'fitness': np.float64(0.6247224761998967)}\n","save_dir: PosixPath('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2')\n","speed: {'preprocess': 0.12273874359636512, 'inference': 0.8317452051216653, 'loss': 0.00037617949088505556, 'postprocess': 0.9918932820570403}\n","stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n","task: 'detect'"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Re-evaluate `vest` Performance (After Helmet Fine-Tuning)"],"metadata":{"id":"CaMSKGpS1dtB"}},{"cell_type":"code","source":["# Reload the updated model\n","model_after = YOLO('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet2/weights/best.pt')"],"metadata":{"id":"utp74OX56P6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on the original vest dataset\n","metrics_after = model_after.val(split='test',\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuhP63sc1Z8Z","executionInfo":{"status":"ok","timestamp":1752496355909,"user_tz":-120,"elapsed":4683,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"a657894e-c146-4d31-c518-4064ce2be23e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.166 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA L4, 22693MiB)\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 29.3Â±17.4 MB/s, size: 72.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/test/labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         49         49    0.00978      0.939      0.106     0.0466\n","          Safety-Vests         49         49    0.00978      0.939      0.106     0.0466\n","Speed: 2.0ms preprocess, 2.6ms inference, 0.0ms loss, 2.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"]}]},{"cell_type":"markdown","source":["# ğŸ’» SolÂ°1: Joint Training"],"metadata":{"id":"Ez_nTrQOOcKl"}},{"cell_type":"code","source":["num_epochs = 30\n","base_path = '/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft'\n","run_prefix = 'yolov8m_alt_ft'\n","\n","initial_weights = 'yolov8m.pt'\n","\n","for epoch in range(num_epochs):\n","    dataset_yaml = (\n","        '/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml' if epoch % 2 == 0\n","        else '/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml'\n","    )\n","\n","    print(f\"ğŸ” Epoch {epoch+1}/{num_epochs} on\", \"Helmet\" if epoch % 2 == 0 else \"Vest\")\n","\n","    # Load from previous epoch's best.pt\n","    if epoch == 0:\n","        model_path = initial_weights\n","    else:\n","        model_path = f\"{base_path}/{run_prefix}{epoch}/weights/best.pt\"\n","\n","    model = YOLO(model_path)\n","\n","    model.train(\n","        data=dataset_yaml,\n","        epochs=1,\n","        resume=False,\n","        imgsz=640,\n","        batch=16,\n","        project=base_path,\n","        name=f'{run_prefix}{epoch+1}',\n","        exist_ok=True\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oyrDqv2AOg-_","executionInfo":{"status":"ok","timestamp":1753135158147,"user_tz":-60,"elapsed":720886,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"7ab39433-a065-4296-a8ae-2129f1a0b107"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ” Epoch 1/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 469/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 29.1Â±12.4 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±0.4 ms, read: 17.9Â±9.3 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      6.74G      1.567      4.031      1.398         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.647      0.716      0.714      0.466\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.647      0.715      0.713      0.466\n","                Helmet         39        154      0.647      0.715      0.713      0.466\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 2.9ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1\u001b[0m\n","ğŸ” Epoch 2/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft1/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 40.9Â±20.8 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 87.4Â±191.4 ms, read: 8.5Â±8.1 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G     0.9238      1.724      1.338          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.687      0.904      0.806      0.475\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.671      0.885      0.772      0.473\n","          Safety-Vests         52         52      0.671      0.885      0.772      0.473\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2\u001b[0m\n","ğŸ” Epoch 3/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft2/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 29.4Â±13.0 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±0.8 ms, read: 18.7Â±11.2 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G      1.795       4.84      1.512         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.499      0.513       0.45      0.241\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.493      0.498       0.45      0.243\n","                Helmet         39        154      0.493      0.498       0.45      0.243\n","Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 1.2ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3\u001b[0m\n","ğŸ” Epoch 4/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft3/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 39.7Â±21.1 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.2 ms, read: 30.1Â±2.9 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.46G     0.8086      1.787      1.239          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52     0.0569      0.462      0.041     0.0167\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52     0.0569      0.462     0.0408      0.017\n","          Safety-Vests         52         52     0.0569      0.462     0.0408      0.017\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4\u001b[0m\n","ğŸ” Epoch 5/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft4/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.3 ms, read: 19.1Â±9.9 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.5Â±2.0 ms, read: 19.4Â±8.8 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.44G      1.789      5.637      1.542         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  4.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154     0.0494      0.227      0.077      0.032\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154     0.0492      0.227     0.0769     0.0319\n","                Helmet         39        154     0.0492      0.227     0.0769     0.0319\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5\u001b[0m\n","ğŸ” Epoch 6/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft5/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 44.6Â±17.7 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.1 ms, read: 25.2Â±6.1 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.44G      0.708     0.8729      1.169          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.925      0.951      0.979      0.724\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.925       0.95      0.979      0.724\n","          Safety-Vests         52         52      0.925       0.95      0.979      0.724\n","Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6\u001b[0m\n","ğŸ” Epoch 7/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft6/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 15.4Â±32.7 ms, read: 9.4Â±9.0 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±0.3 ms, read: 15.4Â±9.0 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G       1.85      6.284      1.532         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.423     0.0714      0.251      0.164\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.423     0.0714      0.251      0.164\n","                Helmet         39        154      0.423     0.0714      0.251      0.164\n","Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7\u001b[0m\n","ğŸ” Epoch 8/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft7/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 47.1Â±17.8 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 3.8Â±5.2 ms, read: 13.9Â±12.9 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.44G     0.6243     0.6896      1.117          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.997      0.962      0.988      0.738\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.998      0.962      0.988      0.741\n","          Safety-Vests         52         52      0.998      0.962      0.988      0.741\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8\u001b[0m\n","ğŸ” Epoch 9/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft8/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft9, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 24.9Â±13.2 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.2Â±0.6 ms, read: 12.1Â±4.9 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G      1.733      6.938      1.503         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.733     0.0714      0.412      0.238\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.733     0.0714      0.412      0.238\n","                Helmet         39        154      0.733     0.0714      0.412      0.238\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9\u001b[0m\n","ğŸ” Epoch 10/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft9/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft10, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 40.6Â±21.0 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.0 ms, read: 27.0Â±10.2 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.46G     0.5854      0.561      1.079          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.981      0.976      0.989      0.793\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.981      0.976      0.989      0.787\n","          Safety-Vests         52         52      0.981      0.976      0.989      0.787\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10\u001b[0m\n","ğŸ” Epoch 11/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft10/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft11, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 28.2Â±13.7 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.0Â±0.6 ms, read: 10.1Â±10.2 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.44G      1.817      7.126      1.516         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.75     0.0779      0.413      0.228\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.75     0.0779      0.413      0.228\n","                Helmet         39        154       0.75     0.0779      0.413      0.228\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11\u001b[0m\n","ğŸ” Epoch 12/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft11/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft12, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 48.2Â±21.1 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.1 ms, read: 36.4Â±16.0 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.47G     0.5617     0.5614      1.063          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.985      0.981      0.995      0.773\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.984      0.981      0.995      0.773\n","          Safety-Vests         52         52      0.984      0.981      0.995      0.773\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12\u001b[0m\n","ğŸ” Epoch 13/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft12/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft13, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 25.2Â±13.7 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.8Â±0.5 ms, read: 14.5Â±15.0 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.44G      1.981      7.941      1.634         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","                Helmet         39        154          0          0          0          0\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13\u001b[0m\n","ğŸ” Epoch 14/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft13/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft14, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.7Â±0.3 ms, read: 39.1Â±17.4 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 23.9Â±51.5 ms, read: 14.9Â±9.8 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.47G     0.5192      0.512      1.029          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52       0.71      0.904      0.715      0.605\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52       0.71      0.904      0.715      0.598\n","          Safety-Vests         52         52       0.71      0.904      0.715      0.598\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14\u001b[0m\n","ğŸ” Epoch 15/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft14/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft15, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.6Â±0.2 ms, read: 23.0Â±9.6 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±0.4 ms, read: 9.9Â±6.6 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.46G      1.783      7.544      1.459         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.66      0.214      0.441      0.234\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.673      0.214      0.447      0.237\n","                Helmet         39        154      0.673      0.214      0.447      0.237\n","Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15\u001b[0m\n","ğŸ” Epoch 16/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft15/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft16, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 26.7Â±17.2 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.2 ms, read: 26.7Â±6.1 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.47G     0.5272     0.4698      1.038          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.904      0.942      0.962      0.713\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52        0.9      0.942      0.961      0.709\n","          Safety-Vests         52         52        0.9      0.942      0.961      0.709\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16\u001b[0m\n","ğŸ” Epoch 17/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft16/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft17, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 29.0Â±11.1 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±0.8 ms, read: 17.3Â±6.7 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G      2.026      8.401      1.592         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.882     0.0974      0.493      0.321\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.882     0.0974      0.493      0.321\n","                Helmet         39        154      0.882     0.0974      0.493      0.321\n","Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17\u001b[0m\n","ğŸ” Epoch 18/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft17/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft18, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 50.5Â±23.1 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.1 ms, read: 28.4Â±13.0 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.47G     0.4733     0.4021          1          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.992      0.865      0.972      0.813\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.992      0.865      0.972      0.814\n","          Safety-Vests         52         52      0.992      0.865      0.972      0.814\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18\u001b[0m\n","ğŸ” Epoch 19/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft18/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft19, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 27.6Â±11.6 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.2Â±0.7 ms, read: 17.0Â±8.8 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.46G      2.025      8.362      1.543         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","                Helmet         39        154          0          0          0          0\n","Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19\u001b[0m\n","ğŸ” Epoch 20/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft19/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft20, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 45.9Â±23.4 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 16.6Â±35.3 ms, read: 16.3Â±14.7 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G     0.4487     0.3614     0.9903          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.362      0.981      0.364       0.31\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.364      0.981      0.364       0.31\n","          Safety-Vests         52         52      0.364      0.981      0.364       0.31\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20\u001b[0m\n","ğŸ” Epoch 21/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft20/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft21, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 26.7Â±10.7 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.9Â±0.7 ms, read: 10.2Â±6.6 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G      2.199      8.512      1.697         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","                Helmet         39        154          0          0          0          0\n","Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21\u001b[0m\n","ğŸ” Epoch 22/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft21/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft22, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 47.6Â±19.3 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.1 ms, read: 30.3Â±4.0 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.48G     0.4378     0.3824     0.9805          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.945      0.923      0.977      0.821\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.945      0.923      0.977      0.818\n","          Safety-Vests         52         52      0.945      0.923      0.977      0.818\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22\u001b[0m\n","ğŸ” Epoch 23/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft22/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft23, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 29.1Â±11.3 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.5Â±1.1 ms, read: 13.6Â±7.7 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G      1.932      8.529      1.486         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154        0.5     0.0195      0.262      0.157\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154        0.5     0.0195      0.262      0.157\n","                Helmet         39        154        0.5     0.0195      0.262      0.157\n","Speed: 0.1ms preprocess, 1.3ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23\u001b[0m\n","ğŸ” Epoch 24/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft23/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft24, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 44.2Â±19.3 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.6Â±0.1 ms, read: 30.9Â±10.8 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.48G     0.4188     0.3366       0.97          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.992          1      0.995      0.856\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.992          1      0.995      0.856\n","          Safety-Vests         52         52      0.992          1      0.995      0.856\n","Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24\u001b[0m\n","ğŸ” Epoch 25/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft24/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft25, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 24.5Â±17.9 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.0Â±0.9 ms, read: 12.7Â±6.0 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.46G       1.94      8.392      1.464         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","                Helmet         39        154          0          0          0          0\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25\u001b[0m\n","ğŸ” Epoch 26/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft25/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft26, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 48.9Â±21.1 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 12.3Â±25.0 ms, read: 13.1Â±12.1 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.47G      0.398     0.3279     0.9607          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.605      0.846       0.66      0.509\n","\n","1 epochs completed in 0.003 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.605      0.846       0.66      0.509\n","          Safety-Vests         52         52      0.605      0.846       0.66      0.509\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26\u001b[0m\n","ğŸ” Epoch 27/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft26/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft27, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 30.5Â±13.7 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±0.8 ms, read: 17.3Â±10.0 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.45G      1.914      8.795      1.486         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  7.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n","                Helmet         39        154          0          0          0          0\n","Speed: 0.1ms preprocess, 1.4ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27\u001b[0m\n","ğŸ” Epoch 28/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft27/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft28, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 34.3Â±16.8 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.2Â±0.7 ms, read: 23.4Â±6.8 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.48G     0.3897     0.3296     0.9527          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.359      0.981      0.378      0.312\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52       0.36      0.981      0.378      0.312\n","          Safety-Vests         52         52       0.36      0.981      0.378      0.312\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28\u001b[0m\n","ğŸ” Epoch 29/30 on Helmet\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft28/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft29, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 22.0Â±10.2 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 1.1Â±0.5 ms, read: 12.5Â±6.0 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.46G      1.869      8.504      1.422         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          1    0.00649      0.503      0.302\n","\n","1 epochs completed in 0.002 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          1    0.00649      0.503      0.302\n","                Helmet         39        154          1    0.00649      0.503      0.302\n","Speed: 0.1ms preprocess, 1.5ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29\u001b[0m\n","ğŸ” Epoch 30/30 on Vest\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft29/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_alt_ft30, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n","  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n","  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n","  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n","  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n","  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n","  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n","  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n","  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n","  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n"," 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n"," 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n"," 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n","Model summary: 169 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n","\n","Transferred 475/475 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 36.6Â±16.6 MB/s, size: 73.6 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/train/labels.cache... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.2 ms, read: 35.0Â±10.8 MB/s, size: 78.7 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/valid/labels.cache... 52 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 52/52 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30\u001b[0m\n","Starting training for 1 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/1      7.48G     0.3592     0.2945     0.9368          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:08<00:00,  6.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.976      0.981      0.993      0.807\n","\n","1 epochs completed in 0.004 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30/weights/last.pt, 52.0MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30/weights/best.pt, 52.0MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         52         52      0.976      0.981      0.993      0.801\n","          Safety-Vests         52         52      0.976      0.981      0.993      0.801\n","Speed: 0.1ms preprocess, 1.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30\u001b[0m\n"]}]},{"cell_type":"code","source":["# Reload the updated model\n","final_model = YOLO('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft/yolov8m_alt_ft30/weights/best.pt')"],"metadata":{"id":"1EE9sFCd4BOv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on the original vest dataset\n","metrics_vest  = final_model.val(split='test',\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1hYwAyk39p1","executionInfo":{"status":"ok","timestamp":1753135303357,"user_tz":-60,"elapsed":5519,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"ef157420-78a0-457b-ef85-9929bf4547ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 92 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 37.2Â±4.8 MB/s, size: 77.0 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/test/labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         49         49      0.986       0.98      0.995      0.837\n","          Safety-Vests         49         49      0.986       0.98      0.995      0.837\n","Speed: 3.7ms preprocess, 2.6ms inference, 0.0ms loss, 5.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val34\u001b[0m\n"]}]},{"cell_type":"code","source":["# Evaluate on the original helmet dataset\n","metrics_helmet  = final_model.val(split='test',\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ii2n6dGe5lQ2","executionInfo":{"status":"ok","timestamp":1753135307563,"user_tz":-60,"elapsed":4204,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"34fd1ae4-90c3-4629-8055-f72ea97a9208"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.4Â±0.2 ms, read: 33.7Â±9.2 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/test/labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.00it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         22         82          0          0          0          0\n","                Helmet         22         82          0          0          0          0\n","Speed: 2.4ms preprocess, 3.0ms inference, 0.0ms loss, 1.4ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val35\u001b[0m\n"]}]},{"cell_type":"code","source":["import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Define the base directory where the epoch folders are stored\n","base_dir = \"/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8m_alt_ft\"\n","prefix = \"yolov8m_alt_ft\"\n","\n","# Initialize lists to store data\n","epochs = []\n","mAP50 = []\n","mAP50_95 = []\n","class_type = []\n","\n","# Loop over all folders with epoch results\n","for epoch in range(1, 31):  # 1 to 30\n","    folder = os.path.join(base_dir, f\"{prefix}{epoch}\")\n","    results_csv = os.path.join(folder, \"results.csv\")\n","\n","    if os.path.exists(results_csv):\n","        df = pd.read_csv(results_csv)\n","        # Take the last row for metrics\n","        last_row = df.iloc[-1]\n","        epochs.append(epoch)\n","        mAP50.append(last_row['metrics/mAP50(B)'])\n","        mAP50_95.append(last_row['metrics/mAP50-95(B)'])\n","        class_type.append(\"Helmet\" if epoch % 2 == 1 else \"Vest\")  # Odd=Helmet, Even=Vest\n","\n","# Create a DataFrame\n","metrics_df = pd.DataFrame({\n","    \"Epoch\": epochs,\n","    \"mAP50\": mAP50,\n","    \"mAP50_95\": mAP50_95,\n","    \"Class\": class_type\n","})\n","\n","# Plot mAP50\n","plt.figure(figsize=(12, 5))\n","for cls in [\"Vest\", \"Helmet\"]:\n","    subset = metrics_df[metrics_df[\"Class\"] == cls]\n","    plt.plot(subset[\"Epoch\"], subset[\"mAP50\"], marker='o', label=f'{cls} mAP50')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"mAP50\")\n","plt.title(\"mAP50 per Epoch (Alternating Helmet/Vest Training)\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot mAP50-95\n","plt.figure(figsize=(12, 5))\n","for cls in [\"Vest\", \"Helmet\"]:\n","    subset = metrics_df[metrics_df[\"Class\"] == cls]\n","    plt.plot(subset[\"Epoch\"], subset[\"mAP50_95\"], marker='o', label=f'{cls} mAP50-95')\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"mAP50-95\")\n","plt.title(\"mAP50-95 per Epoch (Alternating Helmet/Vest Training)\")\n","plt.legend()\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":675},"id":"gGYMFOIZCCSN","executionInfo":{"status":"ok","timestamp":1753135792244,"user_tz":-60,"elapsed":548,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"92b3ecdf-aaeb-42d7-99fc-5f63c4ba8e25"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x500 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# ğŸ’» SolÂ°2: Freezing Layers (didn't work)"],"metadata":{"id":"LdDkCjf_TYbn"}},{"cell_type":"code","source":["# Load previous model weights\n","model_helmet = YOLO('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest/weights/best.pt')"],"metadata":{"id":"2U0JrRjOTf5h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Fine-tune on helmet dataset while keeping vest in class list\n","model_helmet.train(\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml',\n","    epochs=30,  # ğŸ‘ˆ this is the key line (less epochs to overwrite less)\n","    imgsz=640,\n","    project='/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment',\n","    name='yolov8m_helmet_frozen',\n","    freeze=15  # ğŸ‘ˆ this is the key line (blocks 0-14 frozen)\n","\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"y87K4H_uTrKH","executionInfo":{"status":"ok","timestamp":1753128099457,"user_tz":-60,"elapsed":44304,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"998ad702-2abd-47f4-e575-4c36a79c7962"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=15, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_vest/weights/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_helmet_frozen3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n","Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n","\n","Transferred 70/355 items from pretrained weights\n","Freezing layer 'model.0.conv.weight'\n","Freezing layer 'model.0.bn.weight'\n","Freezing layer 'model.0.bn.bias'\n","Freezing layer 'model.1.conv.weight'\n","Freezing layer 'model.1.bn.weight'\n","Freezing layer 'model.1.bn.bias'\n","Freezing layer 'model.2.cv1.conv.weight'\n","Freezing layer 'model.2.cv1.bn.weight'\n","Freezing layer 'model.2.cv1.bn.bias'\n","Freezing layer 'model.2.cv2.conv.weight'\n","Freezing layer 'model.2.cv2.bn.weight'\n","Freezing layer 'model.2.cv2.bn.bias'\n","Freezing layer 'model.2.m.0.cv1.conv.weight'\n","Freezing layer 'model.2.m.0.cv1.bn.weight'\n","Freezing layer 'model.2.m.0.cv1.bn.bias'\n","Freezing layer 'model.2.m.0.cv2.conv.weight'\n","Freezing layer 'model.2.m.0.cv2.bn.weight'\n","Freezing layer 'model.2.m.0.cv2.bn.bias'\n","Freezing layer 'model.3.conv.weight'\n","Freezing layer 'model.3.bn.weight'\n","Freezing layer 'model.3.bn.bias'\n","Freezing layer 'model.4.cv1.conv.weight'\n","Freezing layer 'model.4.cv1.bn.weight'\n","Freezing layer 'model.4.cv1.bn.bias'\n","Freezing layer 'model.4.cv2.conv.weight'\n","Freezing layer 'model.4.cv2.bn.weight'\n","Freezing layer 'model.4.cv2.bn.bias'\n","Freezing layer 'model.4.m.0.cv1.conv.weight'\n","Freezing layer 'model.4.m.0.cv1.bn.weight'\n","Freezing layer 'model.4.m.0.cv1.bn.bias'\n","Freezing layer 'model.4.m.0.cv2.conv.weight'\n","Freezing layer 'model.4.m.0.cv2.bn.weight'\n","Freezing layer 'model.4.m.0.cv2.bn.bias'\n","Freezing layer 'model.4.m.1.cv1.conv.weight'\n","Freezing layer 'model.4.m.1.cv1.bn.weight'\n","Freezing layer 'model.4.m.1.cv1.bn.bias'\n","Freezing layer 'model.4.m.1.cv2.conv.weight'\n","Freezing layer 'model.4.m.1.cv2.bn.weight'\n","Freezing layer 'model.4.m.1.cv2.bn.bias'\n","Freezing layer 'model.5.conv.weight'\n","Freezing layer 'model.5.bn.weight'\n","Freezing layer 'model.5.bn.bias'\n","Freezing layer 'model.6.cv1.conv.weight'\n","Freezing layer 'model.6.cv1.bn.weight'\n","Freezing layer 'model.6.cv1.bn.bias'\n","Freezing layer 'model.6.cv2.conv.weight'\n","Freezing layer 'model.6.cv2.bn.weight'\n","Freezing layer 'model.6.cv2.bn.bias'\n","Freezing layer 'model.6.m.0.cv1.conv.weight'\n","Freezing layer 'model.6.m.0.cv1.bn.weight'\n","Freezing layer 'model.6.m.0.cv1.bn.bias'\n","Freezing layer 'model.6.m.0.cv2.conv.weight'\n","Freezing layer 'model.6.m.0.cv2.bn.weight'\n","Freezing layer 'model.6.m.0.cv2.bn.bias'\n","Freezing layer 'model.6.m.1.cv1.conv.weight'\n","Freezing layer 'model.6.m.1.cv1.bn.weight'\n","Freezing layer 'model.6.m.1.cv1.bn.bias'\n","Freezing layer 'model.6.m.1.cv2.conv.weight'\n","Freezing layer 'model.6.m.1.cv2.bn.weight'\n","Freezing layer 'model.6.m.1.cv2.bn.bias'\n","Freezing layer 'model.7.conv.weight'\n","Freezing layer 'model.7.bn.weight'\n","Freezing layer 'model.7.bn.bias'\n","Freezing layer 'model.8.cv1.conv.weight'\n","Freezing layer 'model.8.cv1.bn.weight'\n","Freezing layer 'model.8.cv1.bn.bias'\n","Freezing layer 'model.8.cv2.conv.weight'\n","Freezing layer 'model.8.cv2.bn.weight'\n","Freezing layer 'model.8.cv2.bn.bias'\n","Freezing layer 'model.8.m.0.cv1.conv.weight'\n","Freezing layer 'model.8.m.0.cv1.bn.weight'\n","Freezing layer 'model.8.m.0.cv1.bn.bias'\n","Freezing layer 'model.8.m.0.cv2.conv.weight'\n","Freezing layer 'model.8.m.0.cv2.bn.weight'\n","Freezing layer 'model.8.m.0.cv2.bn.bias'\n","Freezing layer 'model.9.cv1.conv.weight'\n","Freezing layer 'model.9.cv1.bn.weight'\n","Freezing layer 'model.9.cv1.bn.bias'\n","Freezing layer 'model.9.cv2.conv.weight'\n","Freezing layer 'model.9.cv2.bn.weight'\n","Freezing layer 'model.9.cv2.bn.bias'\n","Freezing layer 'model.12.cv1.conv.weight'\n","Freezing layer 'model.12.cv1.bn.weight'\n","Freezing layer 'model.12.cv1.bn.bias'\n","Freezing layer 'model.12.cv2.conv.weight'\n","Freezing layer 'model.12.cv2.bn.weight'\n","Freezing layer 'model.12.cv2.bn.bias'\n","Freezing layer 'model.12.m.0.cv1.conv.weight'\n","Freezing layer 'model.12.m.0.cv1.bn.weight'\n","Freezing layer 'model.12.m.0.cv1.bn.bias'\n","Freezing layer 'model.12.m.0.cv2.conv.weight'\n","Freezing layer 'model.12.m.0.cv2.bn.weight'\n","Freezing layer 'model.12.m.0.cv2.bn.bias'\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.5Â±0.2 ms, read: 26.7Â±10.8 MB/s, size: 32.4 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/train/labels.cache... 139 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 139/139 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.7Â±0.2 ms, read: 14.6Â±6.5 MB/s, size: 39.1 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/Helmet/helmet_relabelled/valid/labels.cache... 39 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       1/30      1.17G      2.974      4.107      2.535         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  8.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154          0          0          0          0\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       2/30      1.28G      2.812      3.765      2.377         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 12.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154   0.000715     0.0325   0.000417   0.000152\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       3/30      1.28G       2.62      3.474      2.265         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154    0.00083     0.0455    0.00162    0.00044\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       4/30      1.28G       2.61      3.251      2.101         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.77it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154     0.0013     0.0714    0.00935    0.00142\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       5/30      1.28G      2.347      2.963      1.944         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 13.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154    0.00298      0.149     0.0132    0.00439\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       6/30      1.28G      2.325      2.917      1.896         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154    0.00705      0.318     0.0524     0.0185\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       7/30      1.28G      2.205      2.788      1.788         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.352     0.0248      0.105     0.0423\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       8/30      1.28G      2.248      2.667       1.72         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.707     0.0628      0.197     0.0902\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["       9/30      1.28G      2.083      2.569      1.677         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.521       0.13      0.243      0.118\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      10/30      1.28G      2.015       2.47      1.549         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.79it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.506      0.208       0.26       0.12\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      11/30      1.28G      2.019      2.379      1.549         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 16.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.725      0.234      0.372      0.165\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      12/30      1.28G      2.031      2.356      1.553         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.599       0.37      0.456      0.217\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      13/30      1.28G      1.995      2.314      1.553         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.20it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.59      0.401      0.476      0.223\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      14/30      1.28G      1.869      2.089       1.44         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.584      0.416      0.471      0.229\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      15/30      1.28G      1.881        2.2       1.46         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 16.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.673      0.429      0.504      0.258\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      16/30      1.29G      1.847      2.041      1.394         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.09it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154       0.67      0.488      0.545      0.271\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      17/30       1.3G      1.824      1.968      1.392         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.92it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.722      0.489      0.567      0.284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      18/30       1.3G      1.817      1.937      1.415         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.708      0.519      0.576      0.285\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      19/30       1.3G      1.709      1.893      1.357         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.694      0.531      0.579      0.289\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      20/30       1.3G      1.863      1.871      1.381         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.81it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.695      0.545        0.6      0.299\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      21/30       1.3G      1.597      1.871      1.278         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:01<00:00,  5.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  8.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.704      0.545      0.621      0.309\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      22/30      1.31G      1.582       1.81      1.265         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.743      0.565      0.626       0.31\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      23/30      1.31G       1.55       1.83      1.253         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.69it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.748      0.558      0.625      0.305\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      24/30      1.31G      1.563      1.778      1.264         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 13.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.59it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.684      0.571      0.617      0.303\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      25/30      1.31G      1.562      1.723       1.25         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.69it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.667      0.573      0.613      0.307\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      26/30      1.32G      1.545      1.784      1.268         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.00it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.683      0.571      0.624      0.308\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      27/30      1.32G      1.503      1.681       1.22         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.00it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.706      0.591      0.626      0.309\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      28/30      1.32G      1.502      1.668      1.251         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 14.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.709      0.597      0.627      0.311\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      29/30      1.32G      1.581       1.71      1.277         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 15.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.83it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.717      0.597      0.632      0.315\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      30/30      1.32G      1.538       1.62      1.247         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 10.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.715      0.597      0.631      0.315\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","30 epochs completed in 0.010 hours.\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3/weights/last.pt, 6.2MB\n","Optimizer stripped from /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3/weights/best.pt, 6.2MB\n","\n","Validating /content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3/weights/best.pt...\n","Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  9.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         39        154      0.731      0.597      0.631      0.315\n","                Helmet         39        154      0.731      0.597      0.631      0.315\n","Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.2ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([1])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7b6e9841cb50>\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n","curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,\n","              0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,       0.975,\n","            0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,\n","            0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.93617,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,\n","            0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,\n","            0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.91071,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,\n","            0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,     0.90476,\n","            0.90476,     0.90476,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.89394,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,\n","            0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.88571,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,     0.87671,\n","            0.87671,     0.87671,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,     0.86842,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,\n","             0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,      0.8625,     0.85366,     0.85366,     0.85366,     0.85366,     0.85366,     0.85366,     0.85366,     0.82759,     0.82759,     0.82759,     0.82759,     0.82759,\n","            0.82759,     0.82759,     0.82759,     0.82759,     0.82759,     0.82759,     0.82759,     0.82759,     0.82022,     0.82022,     0.82022,     0.82022,     0.82022,     0.82022,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,     0.80435,      0.7732,      0.7732,\n","             0.7732,      0.7732,      0.7732,      0.7732,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,     0.77228,\n","            0.76699,     0.76699,     0.76699,     0.76699,     0.76699,     0.76699,     0.76699,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,\n","            0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,     0.75893,\n","            0.75439,     0.75439,     0.75439,     0.75439,     0.75439,     0.75439,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74576,     0.74167,     0.74167,     0.74167,     0.74167,\n","            0.74167,     0.74167,     0.74167,      0.7377,      0.7377,      0.7377,      0.7377,      0.7377,      0.7377,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,       0.736,     0.71212,\n","            0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.71212,     0.67857,     0.67857,     0.67857,     0.67857,     0.67857,     0.67857,     0.67857,     0.67606,     0.67606,     0.67606,     0.67606,\n","            0.67606,     0.67606,     0.64238,     0.64238,     0.64238,     0.64238,     0.64238,     0.64238,     0.64238,      0.6125,      0.6125,      0.6125,      0.6125,      0.6125,      0.6125,     0.57558,     0.57558,     0.57558,     0.57558,     0.57558,     0.57558,     0.57558,     0.57471,\n","            0.57471,     0.57471,     0.57471,     0.57471,     0.57471,     0.56425,     0.56425,     0.56425,     0.56425,     0.56425,     0.56425,     0.56425,     0.55738,     0.55738,     0.55738,     0.55738,     0.55738,     0.55738,     0.48148,     0.48148,     0.48148,     0.48148,     0.48148,\n","            0.48148,     0.48148,     0.48148,     0.48148,     0.48148,     0.48148,     0.48148,     0.48148,     0.44681,     0.44681,     0.44681,     0.44681,     0.44681,     0.44681,     0.44681,     0.43621,     0.43621,     0.43621,     0.43621,     0.43621,     0.43621,     0.41473,     0.41473,\n","            0.41473,     0.41473,     0.41473,     0.41473,     0.41473,     0.39273,     0.39273,     0.39273,     0.39273,     0.39273,     0.39273,     0.37979,     0.37979,     0.37979,     0.37979,     0.37979,     0.37979,     0.37979,     0.37931,     0.37931,     0.37931,     0.37931,     0.37931,\n","            0.37931,       0.375,       0.375,       0.375,       0.375,       0.375,       0.375,       0.375,     0.35897,     0.35897,     0.35897,     0.35897,     0.35897,     0.35897,     0.27561,     0.27561,     0.27561,     0.27561,     0.27561,     0.27561,     0.27561,      0.2511,      0.2511,\n","             0.2511,      0.2511,      0.2511,      0.2511,     0.22505,     0.22505,     0.22505,     0.22505,     0.22505,     0.22505,     0.22505,     0.21682,     0.21682,     0.21682,     0.21682,     0.21682,     0.21682,       0.213,       0.213,       0.213,       0.213,       0.213,       0.213,\n","              0.213,       0.213,       0.213,       0.213,       0.213,       0.213,       0.213,     0.20877,     0.20877,     0.20877,     0.20877,     0.20877,     0.20877,     0.20134,     0.20134,     0.20134,     0.20134,     0.20134,     0.20134,     0.20134,     0.18818,     0.18818,     0.18818,\n","            0.18818,     0.18818,     0.18818,     0.13466,     0.13466,     0.13466,     0.13466,     0.13466,     0.13466,     0.13466,     0.13099,     0.13099,     0.13099,     0.13099,     0.13099,     0.13099,     0.11981,     0.11981,     0.11981,     0.11981,     0.11981,     0.11981,     0.11981,\n","            0.11004,     0.11004,     0.11004,     0.11004,     0.11004,     0.11004,     0.10277,     0.10277,     0.10277,     0.10277,     0.10277,     0.10277,     0.10277,    0.086986,    0.086986,    0.086986,    0.086986,    0.086986,    0.086986,    0.053333,    0.053333,    0.053333,    0.053333,\n","           0.053333,    0.053333,    0.053333,    0.051292,    0.051292,    0.051292,    0.051292,    0.051292,    0.051292,     0.04026,     0.04026,     0.04026,     0.04026,     0.04026,     0.04026,     0.04026,    0.022076,    0.022076,    0.022076,    0.022076,    0.022076,    0.022076,     0.02055,\n","            0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,     0.02055,    0.015004,    0.015004,    0.015004,    0.015004,    0.015004,    0.015004,    0.015004,     0.01426,     0.01415,    0.014039,    0.013929,\n","           0.013818,    0.013708,    0.013597,    0.013487,    0.013376,    0.013266,    0.013155,    0.013044,    0.012934,    0.012823,    0.012713,    0.012602,    0.012492,    0.012381,    0.012271,     0.01216,     0.01205,    0.011939,    0.011828,    0.011718,    0.011607,    0.011497,    0.011386,\n","           0.011276,    0.011165,    0.011055,    0.010944,    0.010834,    0.010723,    0.010612,    0.010502,    0.010391,    0.010281,     0.01017,     0.01006,   0.0099492,   0.0098386,   0.0097281,   0.0096175,    0.009507,   0.0093964,   0.0092859,   0.0091753,   0.0090648,   0.0089542,   0.0088437,\n","          0.0087331,   0.0086226,   0.0085121,   0.0084015,    0.008291,   0.0081804,   0.0080699,   0.0079593,   0.0078488,   0.0077382,   0.0076277,   0.0075171,   0.0074066,    0.007296,   0.0071855,    0.007075,   0.0069644,   0.0068539,   0.0067433,   0.0066328,   0.0065222,   0.0064117,   0.0063011,\n","          0.0061906,     0.00608,   0.0059695,   0.0058589,   0.0057484,   0.0056379,   0.0055273,   0.0054168,   0.0053062,   0.0051957,   0.0050851,   0.0049746,    0.004864,   0.0047535,   0.0046429,   0.0045324,   0.0044218,   0.0043113,   0.0042008,   0.0040902,   0.0039797,   0.0038691,   0.0037586,\n","           0.003648,   0.0035375,   0.0034269,   0.0033164,   0.0032058,   0.0030953,   0.0029847,   0.0028742,   0.0027637,   0.0026531,   0.0025426,    0.002432,   0.0023215,   0.0022109,   0.0021004,   0.0019898,   0.0018793,   0.0017687,   0.0016582,   0.0015476,   0.0014371,   0.0013266,    0.001216,\n","          0.0011055,  0.00099492,  0.00088437,  0.00077382,  0.00066328,  0.00055273,  0.00044218,  0.00033164,  0.00022109,  0.00011055,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.028219,    0.028219,    0.039489,    0.058822,    0.077082,    0.094065,     0.10832,     0.12389,     0.13904,     0.15225,      0.1659,     0.17876,     0.18897,     0.19821,     0.21046,     0.22162,     0.22844,     0.23884,     0.24904,     0.25801,     0.26871,     0.28119,     0.28737,\n","             0.2982,     0.30602,      0.3151,     0.32104,     0.32855,     0.33246,     0.33226,      0.3344,     0.34433,     0.34778,     0.35659,     0.36147,     0.36786,     0.37249,     0.37725,      0.3825,     0.38664,     0.39141,     0.39449,     0.39811,     0.40179,     0.40369,     0.41104,\n","            0.41492,     0.41902,      0.4231,     0.43161,     0.43505,     0.43657,     0.44277,     0.44656,     0.45117,     0.45648,     0.45907,       0.464,     0.46623,     0.46938,      0.4723,     0.47905,     0.47834,       0.478,     0.48106,     0.48725,     0.49182,     0.49289,     0.49334,\n","            0.49327,     0.49204,     0.49886,     0.49959,     0.50124,      0.5064,     0.51099,     0.51558,     0.51639,     0.51894,     0.52414,     0.52693,     0.53065,     0.53265,     0.53042,     0.53214,     0.53599,     0.53689,     0.53717,     0.54001,     0.54216,     0.54271,     0.54324,\n","            0.54373,     0.54421,     0.54537,     0.54887,     0.54975,     0.55046,     0.55093,      0.5514,     0.55591,     0.55976,     0.56032,     0.55642,     0.55711,     0.56148,     0.56292,     0.56443,     0.56603,     0.56743,      0.5707,     0.57406,     0.57661,     0.57731,     0.57853,\n","             0.5817,     0.58306,     0.58443,     0.58902,     0.59269,       0.597,     0.60145,     0.60401,     0.60509,     0.60159,       0.603,     0.60547,     0.60653,     0.60515,     0.60359,     0.60294,     0.60462,     0.60563,     0.60667,     0.60775,     0.60877,     0.60553,     0.60655,\n","            0.60327,     0.60422,     0.60501,     0.60531,     0.60562,     0.60592,     0.60622,     0.60652,     0.60873,     0.61003,     0.61081,     0.61119,     0.61157,     0.61195,     0.61233,     0.61277,     0.61325,     0.61372,      0.6142,     0.61871,     0.61947,     0.62024,      0.6233,\n","            0.62238,     0.62145,     0.62053,     0.62054,     0.62435,     0.62592,     0.62964,     0.63058,     0.63135,     0.63205,     0.63258,     0.63311,     0.63364,     0.63424,     0.63499,     0.63573,     0.63251,     0.63406,     0.63529,     0.63907,     0.64024,      0.6407,     0.64116,\n","            0.64163,     0.64209,      0.6437,     0.64653,     0.64772,     0.64836,     0.64706,     0.64577,     0.64447,     0.64831,     0.64876,     0.64921,     0.64966,     0.65011,     0.65066,     0.65252,     0.65385,     0.65516,     0.65657,     0.65473,     0.65289,     0.64832,     0.64883,\n","            0.64934,     0.64985,     0.65043,     0.65116,     0.65188,     0.65279,     0.65452,     0.65754,     0.65929,     0.65732,     0.65484,     0.65373,     0.65271,     0.65168,     0.65066,     0.64997,     0.65085,     0.65173,     0.64887,     0.64861,     0.64487,      0.6453,     0.64574,\n","            0.64617,      0.6466,     0.64703,     0.64611,     0.64508,     0.64406,     0.64304,     0.64188,     0.63844,     0.63895,     0.63972,     0.64009,     0.64046,     0.64083,      0.6412,     0.64157,     0.64122,     0.63979,     0.63835,     0.63691,      0.6376,     0.63863,     0.63868,\n","             0.6379,     0.63712,     0.63634,     0.63556,     0.63478,       0.634,     0.63058,     0.62773,      0.6256,      0.6235,     0.62206,     0.62063,     0.61919,     0.61793,     0.61695,     0.61596,     0.61497,     0.61398,     0.61306,     0.61403,     0.61499,     0.61322,     0.61025,\n","            0.61186,     0.61403,     0.61309,     0.61062,     0.60959,     0.61001,     0.61044,     0.61087,     0.61129,     0.61172,       0.611,     0.61014,     0.60928,     0.60842,     0.60756,     0.60669,     0.60607,     0.60566,     0.60524,     0.60482,      0.6044,     0.60398,     0.60357,\n","            0.60315,     0.60273,     0.60231,     0.60189,     0.60147,     0.60105,     0.59994,     0.59767,     0.59539,     0.59589,     0.59659,     0.59728,     0.59669,     0.59492,     0.59315,     0.59249,     0.59388,     0.59528,     0.59668,     0.59695,     0.59714,     0.59733,     0.59751,\n","             0.5977,     0.59789,     0.59807,     0.59826,     0.59845,     0.59863,     0.59882,     0.59901,     0.59922,     0.60001,     0.59693,     0.59993,     0.59835,     0.59677,     0.59518,     0.59548,     0.59597,     0.59645,     0.59693,     0.59741,     0.59481,     0.58585,     0.58677,\n","            0.58769,      0.5909,     0.59137,     0.59184,     0.59231,     0.59277,     0.59317,     0.59153,      0.5899,     0.58826,     0.58946,     0.58871,     0.58796,     0.58721,     0.58646,     0.58571,     0.58495,      0.5842,     0.58253,     0.57895,     0.57369,     0.57307,     0.57364,\n","            0.57324,     0.57284,     0.57243,     0.57203,     0.57162,     0.57122,     0.57081,     0.57041,        0.57,     0.56959,     0.56919,     0.56878,     0.56838,     0.56797,     0.56672,      0.5635,     0.56173,     0.56265,     0.56357,     0.56357,     0.56312,     0.56266,      0.5622,\n","            0.56175,     0.56129,     0.56083,     0.56038,     0.55992,     0.55946,       0.559,     0.55855,     0.55809,     0.55763,     0.55585,     0.55366,     0.55146,     0.55218,     0.55343,     0.54767,     0.54013,     0.53788,     0.53562,     0.53407,      0.5346,     0.53512,     0.53565,\n","            0.53617,       0.536,     0.53542,     0.53484,     0.53426,     0.53368,     0.53309,     0.53251,     0.53193,     0.53134,     0.53076,     0.53017,     0.52932,     0.52702,     0.52472,     0.52302,     0.52339,     0.52376,     0.52412,     0.52449,     0.52485,     0.52522,     0.52506,\n","            0.52463,     0.52419,     0.52376,     0.52332,     0.52288,     0.52245,     0.52201,     0.52157,     0.52113,      0.5207,     0.52026,     0.51982,     0.51938,     0.51894,     0.51851,     0.51838,     0.51825,     0.51812,     0.51799,     0.51786,     0.51773,      0.5176,     0.51747,\n","            0.51734,      0.5172,     0.51707,     0.51694,     0.51681,     0.51668,     0.51655,     0.51642,     0.51629,     0.51615,     0.51602,     0.51589,     0.51576,     0.51563,      0.5155,     0.51537,     0.51524,      0.5151,     0.51497,     0.51484,     0.51471,     0.51458,     0.51445,\n","            0.51432,     0.51418,     0.51405,     0.51392,     0.51379,     0.51366,     0.51353,     0.51339,     0.51326,     0.51313,       0.513,     0.51287,     0.51274,      0.5126,     0.51247,     0.51234,     0.51221,     0.51208,     0.51194,     0.51181,     0.51168,     0.51136,     0.51092,\n","            0.51047,     0.51003,     0.50959,     0.50914,      0.5087,     0.50825,      0.5078,     0.50736,     0.50691,     0.50647,     0.50602,     0.50557,     0.50513,     0.50468,     0.50349,     0.50229,      0.5011,      0.4999,     0.49869,     0.49749,     0.49628,     0.49507,     0.49386,\n","            0.49265,     0.49144,     0.49036,     0.48963,      0.4889,     0.48817,     0.48743,      0.4867,     0.48597,     0.48523,      0.4845,     0.48376,     0.48349,     0.48364,     0.48379,     0.48394,     0.48409,     0.48423,     0.48438,     0.48453,     0.48468,     0.48482,     0.48497,\n","            0.48512,     0.48526,     0.48541,     0.48556,      0.4857,      0.4854,     0.48505,     0.48471,     0.48437,     0.48402,     0.48368,     0.48333,     0.48299,     0.48264,      0.4823,     0.48195,     0.48161,     0.48126,     0.48091,     0.48057,     0.48022,     0.47988,     0.47953,\n","            0.47918,     0.47884,     0.47849,     0.47691,     0.47524,     0.47358,     0.47191,     0.46977,     0.46725,     0.46472,     0.46329,     0.46253,     0.46177,     0.46101,     0.46024,     0.45948,     0.45871,     0.45795,     0.45718,     0.45641,     0.45185,     0.44799,     0.44605,\n","             0.4441,     0.44215,     0.44065,     0.43961,     0.43856,     0.43751,     0.43646,     0.43541,     0.43436,     0.43354,     0.43378,     0.43401,     0.43424,     0.43448,     0.43471,     0.43494,     0.43517,      0.4354,     0.43562,      0.4358,     0.43596,     0.43613,      0.4363,\n","            0.43646,     0.43663,     0.43679,     0.43695,     0.43712,     0.43728,     0.43745,     0.43761,     0.43777,     0.43184,     0.42862,     0.42683,     0.42503,     0.42323,     0.42056,     0.41648,     0.41313,     0.41078,     0.40842,     0.40605,     0.40368,      0.4013,     0.39891,\n","            0.39809,     0.39832,     0.39854,     0.39876,     0.39898,      0.3992,     0.39942,     0.39964,     0.39986,     0.40014,     0.40057,       0.401,     0.40142,     0.40184,     0.40171,     0.40094,     0.40018,     0.39941,     0.39863,     0.39786,     0.39709,     0.39632,     0.39555,\n","            0.39477,       0.394,     0.39306,     0.39205,     0.39104,     0.39004,     0.38903,     0.38802,     0.38701,     0.38599,     0.38518,     0.38465,     0.38411,     0.38357,     0.38303,     0.38249,     0.38194,      0.3814,     0.38086,     0.38032,     0.37978,     0.37923,     0.37869,\n","            0.37815,      0.3776,     0.37706,     0.37218,       0.368,     0.36683,     0.36565,     0.36447,     0.36329,     0.36211,     0.36092,      0.3598,     0.36014,     0.36047,     0.36079,     0.36112,     0.36144,     0.36058,      0.3546,     0.35249,     0.35187,     0.35124,     0.35062,\n","            0.34999,     0.34937,     0.34874,     0.34812,     0.34749,     0.34686,     0.34624,     0.34561,     0.34498,     0.34435,     0.34353,     0.34257,     0.34161,     0.34064,     0.33968,     0.33871,     0.33774,     0.33677,      0.3358,     0.33469,     0.33327,     0.33185,     0.33042,\n","              0.329,     0.32756,     0.32613,     0.32582,     0.32555,     0.32527,       0.325,     0.32472,     0.32445,     0.32417,      0.3239,     0.32362,     0.32335,     0.32307,      0.3228,     0.32252,     0.32225,     0.32197,      0.3217,     0.32142,     0.32114,     0.32087,     0.32059,\n","            0.32032,     0.32004,     0.31976,     0.31949,     0.31921,     0.31893,     0.31866,     0.31838,      0.3181,     0.31783,     0.31755,     0.31727,       0.317,     0.31505,     0.31269,     0.31032,     0.30794,     0.30669,     0.30556,     0.30444,     0.30331,     0.30218,     0.30105,\n","            0.29992,     0.29879,     0.29745,     0.29596,     0.29447,     0.29298,     0.29149,     0.28999,     0.28825,     0.28581,     0.28336,      0.2809,     0.26918,     0.26785,     0.26652,     0.26519,     0.26385,     0.26251,     0.26117,     0.25959,     0.25285,     0.24941,     0.24839,\n","            0.24737,     0.24634,     0.24532,     0.24429,     0.24327,     0.24224,     0.24121,     0.24018,     0.23858,     0.23686,     0.23513,      0.2334,     0.23167,     0.22994,     0.22913,     0.22836,     0.22759,     0.22681,     0.22604,     0.22526,     0.22448,     0.22371,     0.22293,\n","            0.22215,     0.22137,     0.22059,     0.21981,     0.21881,     0.21775,     0.21669,     0.21563,     0.21457,     0.21351,     0.21245,     0.21139,     0.21032,     0.20925,     0.20806,     0.20687,     0.20568,     0.20449,      0.2033,     0.20211,     0.20091,     0.19971,     0.19801,\n","            0.19492,     0.19182,      0.1887,     0.17607,     0.17436,     0.17266,     0.17094,     0.16923,     0.16751,     0.16637,     0.16578,     0.16519,      0.1646,     0.16401,     0.16342,     0.16283,     0.16224,     0.16164,     0.16105,     0.16046,     0.15987,     0.15927,     0.15868,\n","            0.15808,     0.15749,      0.1569,      0.1563,      0.1557,     0.14461,     0.14282,     0.14105,     0.13928,     0.13751,     0.13573,     0.13395,     0.13277,     0.13191,     0.13105,     0.13019,     0.12933,     0.12846,      0.1276,     0.12673,     0.12587,       0.125,     0.12414,\n","            0.12327,      0.1224,     0.12141,     0.12029,     0.11917,     0.11805,     0.11692,      0.1158,     0.11467,     0.11355,     0.11242,     0.11129,     0.10899,     0.10302,    0.097988,    0.095309,    0.092622,    0.089928,    0.087226,    0.075927,    0.074415,    0.073782,    0.073148,\n","           0.072515,     0.07188,    0.071246,    0.070611,    0.069975,    0.069339,    0.068703,    0.068066,    0.067429,    0.066791,    0.066153,    0.065515,    0.064876,    0.064236,    0.063597,    0.062957,    0.062424,    0.061903,    0.061382,    0.060861,     0.06034,    0.059818,    0.059296,\n","           0.058773,    0.058251,    0.057728,    0.057204,    0.056681,    0.056157,    0.055633,    0.055109,    0.054584,    0.054059,    0.053534,    0.053008,    0.052482,    0.051956,     0.05143,    0.050903,    0.044457,    0.037489,    0.036064,    0.034636,    0.033207,    0.031775,    0.030342,\n","           0.028906,    0.027469,    0.026029,    0.025029,    0.024191,    0.023353,    0.022513,    0.021673,    0.020833,    0.019991,    0.019149,    0.018306,    0.017463,    0.016619,    0.015774,    0.014928,    0.014081,    0.013234,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.014342,    0.014342,    0.020206,    0.030473,      0.0404,     0.04983,    0.057966,    0.066977,    0.075919,    0.083868,    0.092308,     0.10034,     0.10694,     0.11302,      0.1212,     0.12866,     0.13347,     0.14083,     0.14797,     0.15435,     0.16207,     0.17123,     0.17584,\n","            0.18402,      0.1904,     0.19748,     0.20261,     0.20863,     0.21228,     0.21314,     0.21544,     0.22375,     0.22728,     0.23486,     0.23912,     0.24474,     0.24886,     0.25389,     0.25867,     0.26247,     0.26689,     0.26976,     0.27316,     0.27757,     0.27938,     0.28647,\n","            0.29026,     0.29429,     0.29833,     0.30686,     0.31035,     0.31189,     0.31826,      0.3222,     0.32702,     0.33263,     0.33539,     0.34067,     0.34308,     0.34651,      0.3497,     0.35715,     0.35749,     0.35756,       0.361,     0.36801,     0.37326,     0.37448,     0.37679,\n","            0.37854,     0.37896,     0.38712,       0.388,      0.3913,     0.39837,     0.40409,     0.40986,     0.41319,     0.41646,      0.4232,     0.42685,     0.43175,     0.43441,     0.43404,     0.43634,     0.44155,     0.44277,     0.44512,     0.44987,     0.45286,     0.45363,     0.45437,\n","            0.45505,     0.45574,     0.45735,      0.4623,     0.46355,     0.46456,     0.46523,      0.4659,     0.47239,     0.47797,     0.48034,      0.4797,     0.48073,     0.48728,     0.48945,     0.49174,     0.49417,     0.49631,     0.50133,     0.50655,     0.51053,     0.51164,     0.51354,\n","            0.51857,     0.52073,     0.52292,     0.53032,      0.5363,      0.5434,     0.55081,     0.55512,     0.55696,     0.55518,     0.55804,     0.56228,     0.56412,      0.5634,     0.56248,     0.56272,     0.56566,     0.56742,     0.56925,     0.57116,     0.57297,      0.5723,     0.57412,\n","            0.57344,     0.57517,     0.57661,     0.57715,      0.5777,     0.57825,      0.5788,     0.57935,      0.5834,     0.58579,     0.58723,     0.58793,     0.58864,     0.58935,     0.59005,     0.59086,     0.59175,     0.59264,     0.59353,     0.60201,     0.60346,     0.60491,       0.612,\n","            0.61149,     0.61097,     0.61046,     0.61148,     0.61893,     0.62203,     0.62941,      0.6313,     0.63283,     0.63425,     0.63532,     0.63639,     0.63746,     0.63868,     0.64019,     0.64169,     0.64191,     0.64511,     0.64766,     0.65556,     0.65804,     0.65902,        0.66,\n","            0.66098,     0.66195,      0.6654,     0.67147,     0.67405,     0.67591,     0.67526,     0.67461,     0.67396,     0.69126,     0.69228,      0.6933,     0.69433,     0.69535,     0.69663,     0.70089,     0.70397,     0.70702,     0.71176,      0.7109,     0.71004,     0.70874,     0.70995,\n","            0.71117,     0.71238,     0.71379,     0.71554,      0.7173,     0.71949,     0.72371,     0.73114,     0.73549,     0.73504,     0.73395,     0.73345,     0.73299,     0.73254,     0.73208,      0.7321,     0.73434,     0.73657,     0.73624,     0.74122,     0.73998,     0.74112,     0.74226,\n","             0.7434,     0.74454,     0.74569,     0.74535,      0.7449,     0.74446,     0.74401,     0.74351,       0.742,     0.74659,      0.7487,     0.74971,     0.75073,     0.75174,     0.75276,     0.75377,     0.75414,     0.75353,     0.75291,      0.7523,      0.7547,      0.7576,     0.75875,\n","            0.75842,     0.75809,     0.75776,     0.75743,      0.7571,     0.75677,     0.75531,     0.75409,     0.75317,     0.75226,     0.75163,     0.75101,     0.75038,     0.74983,     0.74939,     0.74896,     0.74852,     0.74809,     0.74775,     0.75065,     0.75354,     0.75377,     0.75302,\n","            0.75796,     0.76464,     0.76627,     0.76523,     0.76537,     0.76672,     0.76807,     0.76942,     0.77077,     0.77212,     0.77196,      0.7716,     0.77124,     0.77088,     0.77052,     0.77016,      0.7699,     0.76973,     0.76955,     0.76937,      0.7692,     0.76902,     0.76885,\n","            0.76867,     0.76849,     0.76832,     0.76814,     0.76796,     0.76779,     0.76731,     0.76634,     0.76537,     0.76747,     0.76978,     0.77209,     0.77281,     0.77206,     0.77132,     0.77249,     0.77725,     0.78206,     0.78692,     0.78785,      0.7885,     0.78916,     0.78981,\n","            0.79047,     0.79112,     0.79178,     0.79243,     0.79308,     0.79374,     0.79439,     0.79505,     0.79579,     0.80374,     0.80586,     0.81991,     0.81935,     0.81879,     0.81823,     0.81985,     0.82169,     0.82353,     0.82536,      0.8272,     0.82666,     0.82383,     0.82748,\n","            0.83114,     0.84414,     0.84605,     0.84797,     0.84989,      0.8518,     0.85364,     0.85315,     0.85265,     0.85216,     0.86242,      0.8622,     0.86199,     0.86177,     0.86155,     0.86134,     0.86112,     0.86091,     0.86042,     0.85937,     0.85781,     0.86458,     0.86834,\n","            0.86823,     0.86812,       0.868,     0.86789,     0.86777,     0.86766,     0.86755,     0.86743,     0.86732,      0.8672,     0.86709,     0.86697,     0.86686,     0.86675,     0.86639,     0.86546,     0.86641,     0.87083,     0.87525,     0.87663,     0.87651,     0.87638,     0.87626,\n","            0.87614,     0.87601,     0.87589,     0.87577,     0.87564,     0.87552,      0.8754,     0.87528,     0.87515,     0.87503,     0.87454,     0.87394,     0.87334,      0.8786,       0.885,     0.88421,     0.88224,     0.88164,     0.88104,     0.88133,     0.88421,     0.88709,     0.88997,\n","            0.89284,     0.89385,     0.89371,     0.89357,     0.89342,     0.89328,     0.89314,       0.893,     0.89285,     0.89271,     0.89257,     0.89243,     0.89222,     0.89164,     0.89107,     0.89112,     0.89327,     0.89541,     0.89756,     0.89971,     0.90185,       0.904,      0.9047,\n","             0.9046,      0.9045,      0.9044,      0.9043,     0.90421,     0.90411,     0.90401,     0.90391,     0.90381,     0.90371,     0.90362,     0.90352,     0.90342,     0.90332,     0.90322,     0.90319,     0.90316,     0.90313,      0.9031,     0.90307,     0.90304,     0.90301,     0.90298,\n","            0.90295,     0.90292,     0.90289,     0.90286,     0.90283,      0.9028,     0.90277,     0.90274,     0.90271,     0.90268,     0.90265,     0.90262,     0.90259,     0.90256,     0.90253,      0.9025,     0.90247,     0.90244,     0.90241,     0.90238,     0.90235,     0.90232,     0.90229,\n","            0.90226,     0.90223,      0.9022,     0.90217,     0.90214,     0.90211,     0.90208,     0.90204,     0.90201,     0.90198,     0.90195,     0.90192,     0.90189,     0.90186,     0.90183,      0.9018,     0.90177,     0.90174,     0.90171,     0.90168,     0.90165,     0.90158,     0.90147,\n","            0.90137,     0.90126,     0.90116,     0.90105,     0.90095,     0.90084,     0.90074,     0.90063,     0.90053,     0.90042,     0.90032,     0.90021,     0.90011,         0.9,     0.89971,     0.89942,     0.89913,     0.89885,     0.89856,     0.89826,     0.89797,     0.89767,     0.89737,\n","            0.89707,     0.89677,      0.8965,     0.89631,     0.89613,     0.89594,     0.89576,     0.89557,     0.89538,      0.8952,     0.89501,     0.89483,     0.89527,      0.8963,     0.89732,     0.89835,     0.89937,     0.90039,     0.90142,     0.90244,     0.90346,     0.90449,     0.90551,\n","            0.90653,     0.90756,     0.90858,      0.9096,     0.91063,     0.91064,     0.91057,     0.91049,     0.91041,     0.91033,     0.91026,     0.91018,      0.9101,     0.91002,     0.90995,     0.90987,     0.90979,     0.90971,     0.90964,     0.90956,     0.90948,     0.90941,     0.90933,\n","            0.90925,     0.90917,      0.9091,     0.90873,     0.90835,     0.90796,     0.90758,     0.90708,     0.90648,     0.90588,     0.90554,     0.90536,     0.90517,     0.90499,      0.9048,     0.90461,     0.90443,     0.90424,     0.90406,     0.90387,     0.90273,     0.90176,     0.90125,\n","            0.90075,     0.90025,     0.89986,     0.89958,      0.8993,     0.89902,     0.89874,     0.89847,     0.89819,     0.89833,     0.90035,     0.90237,     0.90439,     0.90641,     0.90843,     0.91044,     0.91246,     0.91448,      0.9165,     0.91803,     0.91951,     0.92099,     0.92247,\n","            0.92395,     0.92543,     0.92691,     0.92839,     0.92987,     0.93135,     0.93283,     0.93431,      0.9358,     0.93511,     0.93453,      0.9342,     0.93387,     0.93354,     0.93304,     0.93226,     0.93162,     0.93115,     0.93069,     0.93022,     0.92974,     0.92925,     0.92877,\n","            0.93004,     0.93248,     0.93493,     0.93737,     0.93981,     0.94226,      0.9447,     0.94715,     0.94959,     0.95284,     0.95772,     0.96259,     0.96747,     0.97234,     0.97497,     0.97491,     0.97485,     0.97479,     0.97473,     0.97467,     0.97461,     0.97455,     0.97449,\n","            0.97444,     0.97438,      0.9743,     0.97422,     0.97414,     0.97406,     0.97397,     0.97389,     0.97381,     0.97373,     0.97366,     0.97362,     0.97357,     0.97353,     0.97348,     0.97344,     0.97339,     0.97335,      0.9733,     0.97325,     0.97321,     0.97316,     0.97312,\n","            0.97307,     0.97303,     0.97298,     0.97255,     0.97218,     0.97207,     0.97197,     0.97186,     0.97175,     0.97164,     0.97153,     0.97163,     0.97651,     0.98139,     0.98627,     0.99116,     0.99604,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1,\n","                  1,           1,           1,           1,           1,           1,           1,           1,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.87013,     0.87013,     0.86364,     0.84416,     0.83766,     0.83766,     0.82468,     0.82468,     0.82468,     0.82468,     0.81818,     0.81818,     0.81169,     0.80519,      0.7987,      0.7987,     0.79221,     0.78571,     0.78571,     0.78571,     0.78571,     0.78571,     0.78571,\n","            0.78571,     0.77922,     0.77922,     0.77273,     0.77273,     0.76623,     0.75325,     0.74675,     0.74675,     0.74026,     0.74026,     0.74026,     0.74026,     0.74026,     0.73377,     0.73377,     0.73377,     0.73377,     0.73377,     0.73377,     0.72727,     0.72727,     0.72727,\n","            0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72727,     0.72261,     0.72078,     0.72078,     0.72078,     0.72078,     0.72078,     0.71429,\n","            0.70779,      0.7013,      0.7013,      0.7013,      0.6971,     0.69481,     0.69481,     0.69481,     0.68831,     0.68831,     0.68831,     0.68831,     0.68831,     0.68831,     0.68182,     0.68182,     0.68182,     0.68182,     0.67719,     0.67532,     0.67532,     0.67532,     0.67532,\n","            0.67532,     0.67532,     0.67532,     0.67532,     0.67532,     0.67532,     0.67532,     0.67532,     0.67532,     0.67532,     0.67225,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,\n","            0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.66234,     0.65647,     0.65584,     0.65584,     0.65584,     0.65359,     0.65117,     0.64935,     0.64935,     0.64935,     0.64935,     0.64935,     0.64935,     0.64286,     0.64286,\n","            0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63636,     0.63503,\n","            0.63366,      0.6323,     0.63093,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62987,     0.62338,     0.62338,     0.62338,     0.62338,     0.62338,     0.62338,     0.62338,\n","            0.62338,     0.62338,     0.62338,     0.62338,     0.62338,     0.62297,     0.62113,     0.61929,     0.61746,     0.61039,     0.61039,     0.61039,     0.61039,     0.61039,     0.61039,     0.61039,     0.61039,     0.61039,     0.60933,     0.60679,     0.60425,      0.5974,      0.5974,\n","             0.5974,      0.5974,      0.5974,      0.5974,      0.5974,      0.5974,      0.5974,      0.5974,      0.5974,     0.59446,     0.59113,     0.58964,     0.58827,     0.58691,     0.58554,     0.58442,     0.58442,     0.58442,     0.58004,     0.57657,     0.57143,     0.57143,     0.57143,\n","            0.57143,     0.57143,     0.57143,     0.57019,     0.56886,     0.56752,     0.56619,     0.56469,     0.56026,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55844,     0.55771,     0.55588,     0.55404,     0.55221,     0.55195,     0.55195,     0.55141,\n","            0.55043,     0.54944,     0.54845,     0.54747,     0.54648,      0.5455,     0.54121,     0.53765,     0.53498,     0.53237,     0.53059,     0.52882,     0.52704,     0.52549,     0.52428,     0.52307,     0.52186,     0.52065,     0.51948,     0.51948,     0.51948,     0.51685,     0.51299,\n","            0.51299,     0.51299,     0.51095,     0.50799,     0.50649,     0.50649,     0.50649,     0.50649,     0.50649,     0.50649,     0.50559,     0.50456,     0.50354,     0.50252,     0.50149,     0.50047,     0.49973,     0.49924,     0.49875,     0.49825,     0.49776,     0.49727,     0.49677,\n","            0.49628,     0.49579,     0.49529,      0.4948,     0.49431,     0.49382,     0.49251,     0.48985,     0.48719,     0.48701,     0.48701,     0.48701,     0.48595,      0.4839,     0.48185,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,\n","            0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.48052,     0.47868,     0.47403,     0.47302,     0.47124,     0.46947,     0.46769,     0.46753,     0.46753,     0.46753,     0.46753,     0.46753,     0.46453,     0.45455,     0.45455,\n","            0.45455,     0.45455,     0.45455,     0.45455,     0.45455,     0.45455,     0.45449,     0.45271,     0.45094,     0.44916,     0.44775,     0.44694,     0.44614,     0.44533,     0.44452,     0.44372,     0.44291,      0.4421,     0.44032,     0.43652,     0.43095,     0.42857,     0.42829,\n","            0.42787,     0.42744,     0.42702,      0.4266,     0.42618,     0.42575,     0.42533,     0.42491,     0.42449,     0.42406,     0.42364,     0.42322,      0.4228,     0.42237,     0.42107,     0.41774,     0.41558,     0.41558,     0.41558,     0.41527,     0.41481,     0.41434,     0.41387,\n","             0.4134,     0.41294,     0.41247,       0.412,     0.41154,     0.41107,      0.4106,     0.41013,     0.40967,      0.4092,     0.40739,     0.40517,     0.40295,      0.4026,      0.4026,     0.39669,     0.38921,     0.38699,     0.38477,     0.38312,     0.38312,     0.38312,     0.38312,\n","            0.38312,     0.38277,      0.3822,     0.38163,     0.38107,      0.3805,     0.37993,     0.37937,      0.3788,     0.37823,     0.37767,      0.3771,     0.37628,     0.37406,     0.37184,     0.37013,     0.37013,     0.37013,     0.37013,     0.37013,     0.37013,     0.37013,     0.36986,\n","            0.36945,     0.36903,     0.36861,      0.3682,     0.36778,     0.36737,     0.36695,     0.36653,     0.36612,      0.3657,     0.36529,     0.36487,     0.36445,     0.36404,     0.36363,     0.36351,     0.36338,     0.36326,     0.36314,     0.36301,     0.36289,     0.36277,     0.36264,\n","            0.36252,     0.36239,     0.36227,     0.36215,     0.36202,      0.3619,     0.36177,     0.36165,     0.36153,      0.3614,     0.36128,     0.36116,     0.36103,     0.36091,     0.36078,     0.36066,     0.36054,     0.36041,     0.36029,     0.36016,     0.36004,     0.35992,     0.35979,\n","            0.35967,     0.35955,     0.35942,      0.3593,     0.35917,     0.35905,     0.35893,      0.3588,     0.35868,     0.35855,     0.35843,     0.35831,     0.35818,     0.35806,     0.35794,     0.35781,     0.35769,     0.35756,     0.35744,     0.35732,     0.35719,     0.35689,     0.35648,\n","            0.35606,     0.35565,     0.35523,     0.35481,      0.3544,     0.35398,     0.35357,     0.35315,     0.35273,     0.35232,      0.3519,     0.35149,     0.35107,     0.35065,     0.34955,     0.34844,     0.34733,     0.34623,     0.34512,     0.34401,      0.3429,     0.34179,     0.34068,\n","            0.33957,     0.33846,     0.33748,     0.33681,     0.33614,     0.33548,     0.33481,     0.33415,     0.33348,     0.33282,     0.33215,     0.33148,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33117,\n","            0.33117,     0.33117,     0.33117,     0.33117,     0.33117,     0.33089,     0.33058,     0.33027,     0.32996,     0.32965,     0.32934,     0.32903,     0.32872,     0.32841,      0.3281,     0.32779,     0.32748,     0.32717,     0.32686,     0.32655,     0.32624,     0.32593,     0.32562,\n","            0.32531,       0.325,     0.32469,     0.32328,      0.3218,     0.32033,     0.31885,     0.31696,     0.31474,     0.31252,     0.31127,     0.31061,     0.30994,     0.30928,     0.30861,     0.30794,     0.30728,     0.30661,     0.30595,     0.30528,     0.30134,     0.29803,     0.29636,\n","             0.2947,     0.29304,     0.29176,     0.29087,     0.28999,      0.2891,     0.28821,     0.28732,     0.28644,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,\n","            0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28571,     0.28074,     0.27808,      0.2766,     0.27512,     0.27364,     0.27146,     0.26813,     0.26542,     0.26351,     0.26161,     0.25971,     0.25781,     0.25591,     0.25401,\n","            0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25325,     0.25297,     0.25237,     0.25176,     0.25116,     0.25055,     0.24995,     0.24934,     0.24874,     0.24813,\n","            0.24753,     0.24692,     0.24619,      0.2454,     0.24462,     0.24384,     0.24305,     0.24227,     0.24149,     0.24071,     0.24008,     0.23966,     0.23925,     0.23883,     0.23842,       0.238,     0.23758,     0.23717,     0.23675,     0.23634,     0.23592,      0.2355,     0.23509,\n","            0.23467,     0.23426,     0.23384,     0.23012,     0.22695,     0.22607,     0.22518,     0.22429,      0.2234,     0.22252,     0.22163,     0.22078,     0.22078,     0.22078,     0.22078,     0.22078,     0.22078,     0.21995,     0.21551,     0.21395,     0.21349,     0.21304,     0.21258,\n","            0.21212,     0.21166,      0.2112,     0.21074,     0.21028,     0.20982,     0.20936,      0.2089,     0.20844,     0.20799,     0.20739,     0.20669,     0.20599,     0.20528,     0.20458,     0.20388,     0.20318,     0.20248,     0.20178,     0.20098,     0.19996,     0.19893,     0.19791,\n","            0.19688,     0.19586,     0.19484,     0.19462,     0.19442,     0.19422,     0.19403,     0.19383,     0.19364,     0.19344,     0.19325,     0.19305,     0.19285,     0.19266,     0.19246,     0.19227,     0.19207,     0.19187,     0.19168,     0.19148,     0.19129,     0.19109,      0.1909,\n","             0.1907,      0.1905,     0.19031,     0.19011,     0.18992,     0.18972,     0.18953,     0.18933,     0.18913,     0.18894,     0.18874,     0.18855,     0.18835,     0.18698,     0.18532,     0.18365,     0.18199,     0.18112,     0.18033,     0.17955,     0.17877,     0.17798,      0.1772,\n","            0.17642,     0.17563,     0.17471,     0.17368,     0.17266,     0.17163,     0.17061,     0.16959,     0.16839,     0.16673,     0.16507,      0.1634,     0.15552,     0.15464,     0.15375,     0.15286,     0.15197,     0.15109,      0.1502,     0.14916,     0.14472,     0.14247,     0.14181,\n","            0.14114,     0.14047,     0.13981,     0.13914,     0.13848,     0.13781,     0.13715,     0.13648,     0.13545,     0.13434,     0.13323,     0.13212,     0.13101,      0.1299,     0.12939,      0.1289,     0.12841,     0.12791,     0.12742,     0.12693,     0.12643,     0.12594,     0.12545,\n","            0.12495,     0.12446,     0.12397,     0.12347,     0.12284,     0.12218,     0.12151,     0.12085,     0.12018,     0.11952,     0.11885,     0.11818,     0.11752,     0.11685,     0.11611,     0.11537,     0.11463,     0.11389,     0.11315,     0.11241,     0.11167,     0.11093,     0.10989,\n","            0.10798,     0.10608,     0.10418,    0.096532,    0.095508,    0.094484,     0.09346,    0.092436,    0.091412,    0.090731,    0.090381,     0.09003,     0.08968,     0.08933,    0.088979,    0.088629,    0.088279,    0.087928,    0.087578,    0.087228,    0.086877,    0.086527,    0.086177,\n","           0.085826,    0.085476,    0.085126,    0.084775,    0.084425,    0.077942,    0.076901,    0.075877,    0.074853,    0.073829,    0.072805,    0.071781,    0.071105,    0.070612,    0.070119,    0.069626,    0.069133,     0.06864,    0.068147,    0.067654,    0.067161,    0.066668,    0.066175,\n","           0.065682,    0.065189,    0.064627,    0.063993,     0.06336,    0.062726,    0.062092,    0.061458,    0.060824,     0.06019,    0.059556,    0.058922,    0.057637,    0.054309,    0.051518,    0.050039,     0.04856,    0.047081,    0.045602,    0.039462,    0.038645,    0.038304,    0.037963,\n","           0.037621,     0.03728,    0.036939,    0.036597,    0.036256,    0.035915,    0.035573,    0.035232,    0.034891,    0.034549,    0.034208,    0.033867,    0.033525,    0.033184,    0.032843,    0.032501,    0.032218,     0.03194,    0.031663,    0.031386,    0.031108,    0.030831,    0.030554,\n","           0.030276,    0.029999,    0.029722,    0.029444,    0.029167,     0.02889,    0.028612,    0.028335,    0.028058,     0.02778,    0.027503,    0.027226,    0.026948,    0.026671,    0.026394,    0.026116,    0.022734,    0.019102,    0.018363,    0.017623,    0.016884,    0.016144,    0.015405,\n","           0.014665,    0.013926,    0.013186,    0.012673,    0.012244,    0.011814,    0.011385,    0.010955,    0.010526,    0.010097,   0.0096672,   0.0092378,   0.0088083,   0.0083789,   0.0079495,   0.0075201,   0.0070907,   0.0066612,           0,           0,           0,           0,           0,\n","                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Confidence', 'Recall']]\n","fitness: np.float64(0.3465239088242704)\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([    0.31491,     0.31491])\n","names: {0: 'Safety-Vests', 1: 'Helmet'}\n","nt_per_class: array([  0, 154])\n","nt_per_image: array([ 0, 39])\n","results_dict: {'metrics/precision(B)': np.float64(0.7311373249151026), 'metrics/recall(B)': np.float64(0.5974025974025974), 'metrics/mAP50(B)': np.float64(0.6310232876000902), 'metrics/mAP50-95(B)': np.float64(0.3149128667380682), 'fitness': np.float64(0.3465239088242704)}\n","save_dir: PosixPath('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3')\n","speed: {'preprocess': 0.0968800769232285, 'inference': 0.6327860512847576, 'loss': 0.0005073589608610536, 'postprocess': 1.2006166153953064}\n","stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n","task: 'detect'"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Reload the updated model\n","model_after = YOLO('/content/gdrive/MyDrive/DISAL/Disal-Data/runs/detect/yolo_finetune_retention_experiment/yolov8n_helmet_frozen3/weights/best.pt')"],"metadata":{"id":"MuPs1-sHVlHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate on the original vest dataset\n","metrics_after = model_after.val(split='test',\n","    data='/content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/data.yaml'\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wCixUtF8WCyl","executionInfo":{"status":"ok","timestamp":1753128170571,"user_tz":-60,"elapsed":4302,"user":{"displayName":"Donia Gasmi","userId":"11474185005055033912"}},"outputId":"da483007-5d0f-4bb2-f16d-f39f843480b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.168 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n","Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 52.0Â±15.0 MB/s, size: 89.9 KB)\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/DISAL/Disal-Data/Objects/SafetyVest/safetyvest_1k/test/labels.cache... 49 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49/49 [00:00<?, ?it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         49         49    0.00539       0.51     0.0123    0.00225\n","          Safety-Vests         49         49    0.00539       0.51     0.0123    0.00225\n","Speed: 3.2ms preprocess, 1.1ms inference, 0.0ms loss, 3.7ms postprocess per image\n","Results saved to \u001b[1mruns/detect/val9\u001b[0m\n"]}]}]}